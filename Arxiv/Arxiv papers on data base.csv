"","title","author","subject","abstract","meta"
"1","Positioning Error Impact Compensation through Data-Driven Optimization in User-Centric Networks","Waseem Raza, Fahd Ahmed Khan, Muhammad Umar Bin Farooq, Sabit Ekin, Ali Imran","Systems and Control (eess.SY)","The performance of user-centric ultra-dense networks (UCUDNs) hinges on the Service zone (Szone) radius, which is an elastic parameter that balances the area spectral efficiency (ASE) and energy efficiency (EE) of the network. Accurately determining the Szone radius requires the precise location of the user equipment (UE) and data base stations (DBSs). Even a slight error in reported positions of DBSs or UE will lead to an incorrect determination of Szone radius and UE-DBS pairing, leading to degradation of the UE-DBS communication link. To compensate for the positioning error impact and improve the ASE and EE of the UCUDN, this work proposes a data-driven optimization and error compensation (DD-OEC) framework. The framework comprises an additional machine learning model that assesses the impact of residual errors and regulates the erroneous datadriven optimization to output Szone radius, transmit power, and DBS density values which improve network ASE and EE. The performance of the framework is compared to a baseline scheme, which does not employ the residual, and results demonstrate that the DD-OEC framework outperforms the baseline, achieving up to a 23% improvement in performance.","Sat, 24 Feb 2024 11:47:22 UTC (3,430 KB)"
"2","Estimation of Spectral Risk Measure for Left Truncated and Right Censored Data","Suparna Biswas, Rituparna Sen","Methodology (stat.ME)","Left truncated and right censored data are encountered frequently in insurance loss data due to deductibles and policy limits. Risk estimation is an important task in insurance as it is a necessary step for determining premiums under various policy terms. Spectral risk measures are inherently coherent and have the benefit of connecting the risk measure to the user's risk aversion. In this paper we study the estimation of spectral risk measure based on left truncated and right censored data. We propose a non parametric estimator of spectral risk measure using the product limit estimator and establish the asymptotic normality for our proposed estimator. We also develop an Edgeworth expansion of our proposed estimator. The bootstrap is employed to approximate the distribution of our proposed estimator and shown to be second order ``accurate''. Monte Carlo studies are conducted to compare the proposed spectral risk measure estimator with the existing parametric and non parametric estimators for left truncated and right censored data. Based on our simulation study we estimate the exponential spectral risk measure for three data sets viz; Norwegian fire claims data set, Spain automobile insurance claims and French marine losses.","Thu, 22 Feb 2024 06:25:10 UTC (305 KB)"
"3","Explainable Classification Techniques for Quantum Dot Device Measurements","Daniel Schug, Tyler J. Kovach, M. A. Wolfe, Jared Benson, Sanghyeok Park, J. P. Dodson, J. Corrigan, M. A. Eriksson, Justyna P. Zwolak","Computer Vision and Pattern Recognition (cs.CV)","In the physical sciences, there is an increased need for robust feature representations of image data: image acquisition, in the generalized sense of two-dimensional data, is now widespread across a large number of fields, including quantum information science, which we consider here. While traditional image features are widely utilized in such cases, their use is rapidly being supplanted by Neural Network-based techniques that often sacrifice explainability in exchange for high accuracy. To ameliorate this trade-off, we propose a synthetic data-based technique that results in explainable features. We show, using Explainable Boosting Machines (EBMs), that this method offers superior explainability without sacrificing accuracy. Specifically, we show that there is a meaningful benefit to this technique in the context of quantum dot tuning, where human intervention is necessary at the current stage of development.","Wed, 21 Feb 2024 11:00:23 UTC (3,494 KB)[v2] Fri, 23 Feb 2024 18:31:45 UTC (3,494 KB)"
"4","On new tests for the Poisson distribution based on empirical weight functions","Winnie Kirui, Elzanie Bothma, Marius Smuts, Anke Steyn, Jaco Visagie","Methodology (stat.ME)","We propose new goodness-of-fit tests for the Poisson distribution. The testing procedure entails fitting a weighted Poisson distribution, which has the Poisson as a special case, to observed data. Based on sample data, we calculate an empirical weight function which is compared to its theoretical counterpart under the Poisson assumption. Weighted Lp distances between these empirical and theoretical functions are proposed as test statistics and closed form expressions are derived for L1, L2 and L1 distances. A Monte Carlo study is included in which the newly proposed tests are shown to be powerful when compared to existing tests, especially in the case of overdispersed alternatives. We demonstrate the use of the tests with two practical examples.","Tue, 20 Feb 2024 09:57:46 UTC (28 KB)"
"5","Generating Survival Interpretable Trajectories and Data","Andrei V. Konstantinov, Stanislav R. Kirpichenko, Lev V. Utkin","Machine Learning (cs.LG)","A new model for generating survival trajectories and data based on applying an autoencoder of a specific structure is proposed. It solves three tasks. First, it provides predictions in the form of the expected event time and the survival function for a new generated feature vector on the basis of the Beran estimator. Second, the model generates additional data based on a given training set that would supplement the original dataset. Third, the most important, it generates a prototype time-dependent trajectory for an object, which characterizes how features of the object could be changed to achieve a different time to an event. The trajectory can be viewed as a type of the counterfactual explanation. The proposed model is robust during training and inference due to a specific weighting scheme incorporating into the variational autoencoder. The model also determines the censored indicators of new generated data by solving a classification task. The paper demonstrates the efficiency and properties of the proposed model using numerical experiments on synthetic and real datasets. The code of the algorithm implementing the proposed model is publicly available.","Mon, 19 Feb 2024 18:02:10 UTC (4,150 KB)"
"6","Simple model for the kinetics of stimuli-responsive gels with porous structures","Yuhei Yamada, Shingo Maeda","Soft Condensed Matter (cond-mat.soft)","Stimuli-responsive gels are the gels that vary the volume depending on environmental conditions. It has been reported that the stimuli-responsive gel with an inhomogeneous structure exhibits faster volume change than the gel without it. It is understood as a difference in the transfer dynamics of the solvent, though, there are few models for discussing the effect of inhomogeneity explicitly. In this paper, we propose a simple model for the kinetics of volume change by introducing inhomogeneity as the probability distribution for a random variable that characterizes the structure. Under this framework, we demonstrate that inhomogeneity actually increases the rate of volume change. Furthermore, through analysis of a simplified example, we show that some features that are often seen in experiments can be reproduced by the model. This model provides a simple equation for the time series of volume change that can be used to characterize the experimental data based on a simple physical picture of the phenomenon.","Mon, 19 Feb 2024 17:24:35 UTC (45 KB)"
"7","Amplifying Training Data Exposure through Fine-Tuning with Pseudo-Labeled Memberships","Myung Gyo Oh, Hong Eun Ahn, Leo Hyun Park, Taekyoung Kwon","Computation and Language (cs.CL)","Neural language models (LMs) are vulnerable to training data extraction attacks due to data memorization. This paper introduces a novel attack scenario wherein an attacker adversarially fine-tunes pre-trained LMs to amplify the exposure of the original training data. This strategy differs from prior studies by aiming to intensify the LM's retention of its pre-training dataset. To achieve this, the attacker needs to collect generated texts that are closely aligned with the pre-training data. However, without knowledge of the actual dataset, quantifying the amount of pre-training data within generated texts is challenging. To address this, we propose the use of pseudo-labels for these generated texts, leveraging membership approximations indicated by machine-generated probabilities from the target LM. We subsequently fine-tune the LM to favor generations with higher likelihoods of originating from the pre-training data, based on their membership probabilities. Our empirical findings indicate a remarkable outcome: LMs with over 1B parameters exhibit a four to eight-fold increase in training data exposure. We discuss potential mitigations and suggest future research directions.","Mon, 19 Feb 2024 14:52:50 UTC (277 KB)"
"8","Yamdb: easily accessible thermophysical properties of liquid metals and molten salts","Tom Weier, William Nash, Paolo Personnettaz, Norbert Weber","Materials Science (cond-mat.mtrl-sci)","Yamdb (Yet another materials data base) addresses the need to provide thermophysical properties of liquid metals and molten salts in an easily accessible manner. Mathematical relations describing material properties - usually determined by experiment - are taken from the literature. Equations and their coefficients are stored separately. The former can be implemented in any programming language (Python and Go in this case) and the latter are kept in YAML files together with additional information (source, temperature range, composition, accuracy if available, etc).","Sun, 28 Jan 2024 15:20:12 UTC (313 KB)"
"9","DeepSRGM -- Sequence Classification and Ranking in Indian Classical Music with Deep Learning","Sathwik Tejaswi Madhusudhan, Girish Chowdhary","Sound (cs.SD)","A vital aspect of Indian Classical Music (ICM) is Raga, which serves as a melodic framework for compositions and improvisations alike. Raga Recognition is an important music information retrieval task in ICM as it can aid numerous downstream applications ranging from music recommendations to organizing huge music collections. In this work, we propose a deep learning based approach to Raga recognition. Our approach employs efficient pre possessing and learns temporal sequences in music data using Long Short Term Memory based Recurrent Neural Networks (LSTM-RNN). We train and test the network on smaller sequences sampled from the original audio while the final inference is performed on the audio as a whole. Our method achieves an accuracy of 88.1% and 97 % during inference on the Comp Music Carnatic dataset and its 10 Raga subset respectively making it the state-of-the-art for the Raga recognition task. Our approach also enables sequence ranking which aids us in retrieving melodic patterns from a given music data base that are closely related to the presented query sequence.","Thu, 15 Feb 2024 18:11:02 UTC (557 KB)"
"10","Review of the Learning-based Camera and Lidar Simulation Methods for Autonomous Driving Systems","Hamed Haghighi, Xiaomeng Wang, Hao Jing, Mehrdad Dianati","Computer Vision and Pattern Recognition (cs.CV)","Perception sensors, particularly camera and Lidar, are key elements of Autonomous Driving Systems (ADS) that enable them to comprehend their surroundings for informed driving and control decisions. Therefore, developing realistic camera and Lidar simulation methods, also known as camera and Lidar models, is of paramount importance to effectively conduct simulation-based testing for ADS. Moreover, the rise of deep learning-based perception models has propelled the prevalence of perception sensor models as valuable tools for synthesising diverse training datasets. The traditional sensor simulation methods rely on computationally expensive physics-based algorithms, specifically in complex systems such as ADS. Hence, the current potential resides in learning-based models, driven by the success of deep generative models in synthesising high-dimensional data. This paper reviews the current state-of-the-art in learning-based sensor simulation methods and validation approaches, focusing on two main types of perception sensors: cameras and Lidars. This review covers two categories of learning-based approaches, namely raw-data-based and object-based models. Raw-data-based methods are explained concerning the employed learning strategy, while object-based models are categorised based on the type of error considered. Finally, the paper illustrates commonly used validation techniques for evaluating perception sensor models and highlights the existing research gaps in the area.","Mon, 29 Jan 2024 16:56:17 UTC (9,918 KB)"
"11","An Approximation Based Theory of Linear Regression","Laurie Davies","Methodology (stat.ME)","The goal of this paper is to provide a theory linear regression based entirely on approximations. It will be argued that the standard linear regression model based theory whether frequentist or Bayesian has failed and that this failure is due to an 'assumed (revealed?) truth' (John Tukey) attitude to the models. This is reflected in the language of statistical inference which involves a concept of truth, for example efficiency, consistency and hypothesis testing. The motivation behind this paper was to remove the word `true' from the theory and practice of linear regression and to replace it by approximation. The approximations considered are the least squares approximations. An approximation is called valid if it contains no irrelevant covariates. This is operationalized using the concept of a Gaussian P-value which is the probability that pure Gaussian noise is better in term of least squares than the covariate. The precise definition given in the paper is intuitive and requires only four simple equations. Given this a valid approximation is one where all the Gaussian P-values are less than a threshold $p0$ specified by the statistician, in this paper with the default value 0.01. This approximations approach is not only much simpler it is overwhelmingly better than the standard model based approach. This will be demonstrated using six real data sets, four from high dimensional regression and two from vector autoregression. Both the simplicity and the superiority of Gaussian P-values derive from their universal exactness and validity. This is in complete contrast to standard F P-values which are valid only for carefully designed simulations. The paper contains excerpts from an unpublished paper by John Tukey entitled `Issues relevant to an honest account of data-based inference partially in the light of Laurie Davies's paper'.","Thu, 15 Feb 2024 10:23:48 UTC (702 KB)"
"12","Permittivity Estimation in Ray-tracing Using Path Loss Data based on GAMP","Yuanhao Jiang, Shidong Zhou, Xiaofeng Zhong","Signal Processing (eess.SP)","In this paper, we propose a modified Generalized Approximate Message Passing (GAMP) algorithm to estimate permittivity parameters using path loss data in ray-tracing model.","Wed, 14 Feb 2024 13:43:10 UTC (76 KB)"
"13","Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NCEP-NWP forecasts","Apoorva Narula, Aastha Jain, Jatin Batra, Sandeep Juneja","Machine Learning (cs.LG)","In this draft we consider the problem of forecasting rainfall across India during the four monsoon months, one day as well as three days in advance. We train neural networks using historical daily gridded precipitation data for India obtained from IMD for the time period $1901- 2022$, at a spatial resolution of $1^{\circ} \times 1^{\circ}$. This is compared with the numerical weather prediction (NWP) forecasts obtained from NCEP (National Centre for Environmental Prediction) available for the period 2011-2022. We conduct a detailed country wide analysis and separately analyze some of the most populated cities in India. Our conclusion is that forecasts obtained by applying deep learning to historical rainfall data are more accurate compared to NWP forecasts as well as predictions based on persistence. On average, compared to our predictions, forecasts from NCEP-NWP model have about 34% higher error for a single day prediction, and over 68% higher error for a three day prediction. Similarly, persistence estimates report a 29% higher error in a single day forecast, and over 54% error in a three day forecast. We further observe that data up to 20 days in the past is useful in reducing errors of one and three day forecasts, when a transformer based learning architecture, and to a lesser extent when an LSTM is used. A key conclusion suggested by our preliminary analysis is that NWP forecasts can be substantially improved upon through more and diverse data relevant to monsoon prediction combined with carefully selected neural network architecture.","Mon, 12 Feb 2024 17:59:20 UTC (27,478 KB)"
"14","Physics-informed machine learning as a kernel method","Nathan Doumèche (LPSM, EDF R&D OSIRIS), Francis Bach (DI-ENS), Claire Boyer (IUF, LPSM), Gérard Biau (LPSM)","Artificial Intelligence (cs.AI)","Physics-informed machine learning combines the expressiveness of data-based approaches with the interpretability of physical models. In this context, we consider a general regression problem where the empirical risk is regularized by a partial differential equation that quantifies the physical inconsistency. We prove that for linear differential priors, the problem can be formulated as a kernel regression task. Taking advantage of kernel theory, we derive convergence rates for the minimizer of the regularized risk and show that it converges at least at the Sobolev minimax rate. However, faster rates can be achieved, depending on the physical error. This principle is illustrated with a one-dimensional example, supporting the claim that regularizing the empirical risk with physical information can be beneficial to the statistical performance of estimators.","Mon, 12 Feb 2024 09:38:42 UTC (1,863 KB)"
"15","Multi-class real-time crash risk forecasting using convolutional neural network: Istanbul case study","Behnaz Alafi, Saeid Moradi","Machine Learning (cs.LG)","The performance of an artificial neural network (ANN) in forecasting crash risk is shown in this paper. To begin, some traffic and weather data are acquired as raw data. This data is then analyzed, and relevant characteristics are chosen to utilize as input data based on additional tree and Pearson correlation. Furthermore, crash and non-crash time data are separated; then, feature values for crash and non-crash events are written in three four-minute intervals prior to the crash and non-crash events using the average of all available values for that period. The number of non-crash samples was lowered after calculating crash likelihood for each period based on accident labeling. The proposed CNN model is capable of learning from recorded, processed, and categorized input characteristics such as traffic characteristics and meteorological conditions. The goal of this work is to forecast the chance of a real-time crash based on three periods before events. The area under the curve (AUC) for the receiver operating characteristic curve (ROC curve), as well as sensitivity as the true positive rate and specificity as the false positive rate, are shown and compared with three typical machine learning and neural network models. Finally, when it comes to the error value, AUC, sensitivity, and specificity parameters as performance variables, the executed model outperforms other models. The findings of this research suggest applying the CNN model as a multi-class prediction model for real-time crash risk prediction. Our emphasis is on multi-class prediction, while prior research used this for binary (two-class) categorization like crash and non-crash.","Fri, 9 Feb 2024 10:51:09 UTC (1,147 KB)"
"16","Neuronal functional connectivity graph estimation with the R package neurofuncon","Lauren Miako Beede, Giuseppe Vinci","Neurons and Cognition (q-bio.NC)","Researchers continue exploring neurons' intricate patterns of activity in the cerebral visual cortex in response to visual stimuli. The way neurons communicate and optimize their interactions with each other under different experimental conditions remains a topic of active investigation. Probabilistic Graphical Models are invaluable tools in neuroscience research, as they let us identify the functional connections, or conditional statistical dependencies, between neurons. Graphical models represent these connections as a graph, where nodes represent neurons and edges indicate the presence of functional connections between them. We developed the R package neurofuncon for the computation and visualization of functional connectivity graphs from large-scale data based on the Graphical lasso. We illustrate the use of this package with publicly available two-photon calcium microscopy imaging data from approximately 10000 neurons in a 1mm cubic section of a mouse visual cortex.","Thu, 8 Feb 2024 18:42:04 UTC (1,656 KB)"
"17","Nature of the diffuse emission sources in the H I supershell in the galaxy IC 1613","Anastasiya D. Yarovova, Alexei V. Moiseev, Ivan S. Gerasimov, Milica M. Vučetić, Oleg V. Egorov, Dragana Ilić, Ilya A. Mereminskiy, Yury V. Pakhomov, Olga N. Sholukhova","Astrophysics of Galaxies (astro-ph.GA)","We present a study of the nearby low-metallicity dwarf galaxy IC 1613, focusing on the search for massive stars and related feedback processes, as well as for faint supernova remnants (SNR) in late stages of evolution. We obtained the deepest images of IC 1613 in the narrow-band H{\alpha}, He II and [S II] emission lines and new long-slit spectroscopy observations using several facilities (6-m BTA, 2.5m SAI MSU, and 150RTT telescopes), in combination with the multi-wavelength archival data from MUSE/VLT, VLA, XMM-Newton, and Swift/XRT. Our deep narrow-band photometry identifies several faint shells in the galaxy, and we further investigate their physical characteristics with the new long-slit spectroscopy observations and the archival multi-wavelength data. Based on energy balance calculations and assumptions about their possible nature, we propose that one of the shells is a possible remnant of a supernova explosion. We study five out of eight Wolf-Rayet (WR) star candidates previously published for this galaxy using the He ii emission line mapping, MUSE/VLT archival spectra, and new long-slit spectra. Our analysis discards the considered WR candidates and finds no new ones. We found P Cyg profiles in H{\alpha} line in two stars, which we classify as Luminous Blue Variable (LBV) star candidates. Overall, the galaxy IC 1613 may have a lower rate of WR star formation than previously suggested.","Wed, 7 Feb 2024 18:57:52 UTC (5,068 KB)"
"18","Competitive advantage of URLLC vs. eMBB for supporting timeliness-relevant services","Luis Guijarro, Jose-Ramon Vidal, Vicent Pla","Networking and Internet Architecture (cs.NI)","5G specifications promise a common and flexible-enough network infrastructure capable of satisfying diverse requirements of both current and future use cases. Two service types standardized in 5G are eMBB, without stringent delay guarantee, and URLLC, with stringent delay guarantee. We focus on a use case where data timeliness is the relevant quality parameter. We provide an economic rationale for the support of data-based services, that is, from the point of view of the profits attained by the service providers and operators (SP). More specifically, we focus on data-based services the quality of which is related to the Age of Information, and we assess two alternatives for the support of this sort of services by means of a 5G network: one that is based on the eMBB service type, and one that is based on the URLLC service type. These assessment is conducted in a duopoly scenario. We conclude that URLLC support provides a competitive advantage to an SP against a competitor SP that supports its service offering on eMBB. And that there is a slightly better situation for the users when the URLLC QoS constraint is stringent.","Tue, 6 Feb 2024 11:44:50 UTC (441 KB)"
"19","Absolute convergence and error thresholds in non-active adaptive sampling","Manuel Vilares Ferro, Victor M. Darriba Bilbao, Jesús Vilares Ferro","Computation and Language (cs.CL)","Non-active adaptive sampling is a way of building machine learning models from a training data base which are supposed to dynamically and automatically derive guaranteed sample size. In this context and regardless of the strategy used in both scheduling and generating of weak predictors, a proposal for calculating absolute convergence and error thresholds is described. We not only make it possible to establish when the quality of the model no longer increases, but also supplies a proximity condition to estimate in absolute terms how close it is to achieving such a goal, thus supporting decision making for fine-tuning learning parameters in model selection. The technique proves its correctness and completeness with respect to our working hypotheses, in addition to strengthening the robustness of the sampling scheme. Tests meet our expectations and illustrate the proposal in the domain of natural language processing, taking the generation of part-of-speech taggers as case study.","Sun, 4 Feb 2024 15:10:34 UTC (688 KB)"
"20","Adaptive scheduling for adaptive sampling in POS taggers construction","Manuel Vilares Ferro, Victor M. Darriba Bilbao, Jesús Vilares Ferro","Computation and Language (cs.CL)","We introduce an adaptive scheduling for adaptive sampling as a novel way of machine learning in the construction of part-of-speech taggers. The goal is to speed up the training on large data sets, without significant loss of performance with regard to an optimal configuration. In contrast to previous methods using a random, fixed or regularly rising spacing between the instances, ours analyzes the shape of the learning curve geometrically in conjunction with a functional model to increase or decrease it at any time. The algorithm proves to be formally correct regarding our working hypotheses. Namely, given a case, the following one is the nearest ensuring a net gain of learning ability from the former, it being possible to modulate the level of requirement for this condition. We also improve the robustness of sampling by paying greater attention to those regions of the training data base subject to a temporary inflation in performance, thus preventing the learning from stopping prematurely. The proposal has been evaluated on the basis of its reliability to identify the convergence of models, corroborating our expectations. While a concrete halting condition is used for testing, users can choose any condition whatsoever to suit their own specific needs.","Sun, 4 Feb 2024 15:02:17 UTC (590 KB)"
"21","Modeling of learning curves with applications to pos tagging","Manuel Vilares Ferro, Victor M. Darriba Bilbao, Francisco J. Ribadas Pena","Computation and Language (cs.CL)","An algorithm to estimate the evolution of learning curves on the whole of a training data base, based on the results obtained from a portion and using a functional strategy, is introduced. We approximate iteratively the sought value at the desired time, independently of the learning technique used and once a point in the process, called prediction level, has been passed. The proposal proves to be formally correct with respect to our working hypotheses and includes a reliable proximity condition. This allows the user to fix a convergence threshold with respect to the accuracy finally achievable, which extends the concept of stopping criterion and seems to be effective even in the presence of distorting observations. Our aim is to evaluate the training effort, supporting decision making in order to reduce the need for both human and computational resources during the learning process. The proposal is of interest in at least three operational procedures. The first is the anticipation of accuracy gain, with the purpose of measuring how much work is needed to achieve a certain degree of performance. The second relates the comparison of efficiency between systems at training time, with the objective of completing this task only for the one that best suits our requirements. The prediction of accuracy is also a valuable item of information for customizing systems, since we can estimate in advance the impact of settings on both the performance and the development costs. Using the generation of part-of-speech taggers as an example application, the experimental results are consistent with our expectations.","Sun, 4 Feb 2024 15:00:52 UTC (397 KB)"
"22","Baryon Spin and Emergent Hadron Mass","Peng Cheng","High Energy Physics - Phenomenology (hep-ph)","This thesis describes the use of Dyson-Schwinger equations (DSEs) to study baryon bound states in QCD. In this work, octet baryon axial form factors are calculated using a symmetry-preserving treatment of a vector $\times$ vector contact interaction (SCI). The baryons are considered as quark-plus-interacting-diquark bound states, whose structure (wave function) is obtained by solving a Poincaré-covariant Faddeev equation. Since it preserves symmetries, all consequences of partial conservation of the axial current are manifest. For instance, one finds that octet baryon axial properties are consistent with only minor violations of SU(3)-flavour symmetry, being interpreted as a dynamical consequence of emergent hadron mass (EHM). Considering neutral axial currents, the SCI delivers predictions for the flavour separation of octet baryon axial charges and, consequently, produces values for the associated SU(3) singlet, triplet, and octet axial charges. The results indicate that, at the hadron scale $\zeta_{\mathcal{H}}$, valence degrees of freedom carry approximately $50\%$ of an octet baryon's total spin. Proton structure is one of the principal topics in hadron physics. Its study is expected to reveal key features of both the origin of mass and strong interaction dynamics. This work therefore extended the above analyses to an examination of in-proton parton helicity (spin) distribution functions (DFs). Using Ansätze for hadron-scale proton polarised valence quark DFs, predictions are delivered for all proton polarised DFs at the measurement scale $\zeta_{\rm C}^2 = 3\,$GeV$^2$. The pointwise behaviour of the predicted DFs and, consequently, their moments, shows good agreement with results inferred from data. Based on these results, one finds that experimental measurements of the proton flavour-singlet axial charge should return a value $a_0^{\rm E}(\zeta_{\rm C}) = 0.35(2)$.","Fri, 2 Feb 2024 13:57:29 UTC (1,890 KB)"
"23","A comparison study of supervised learning techniques for the approximation of high dimensional functions and feedback control","Mathias Oster, Luca Saluzzi, Tizian Wenzel","Numerical Analysis (math.NA)","Approximation of high dimensional functions is in the focus of machine learning and data-based scientific computing. In many applications, empirical risk minimisation techniques over nonlinear model classes are employed. Neural networks, kernel methods and tensor decomposition techniques are among the most popular model classes. We provide a numerical study comparing the performance of these methods on various high-dimensional functions with focus on optimal control problems, where the collection of the dataset is based on the application of the State-Dependent Riccati Equation.","Fri, 2 Feb 2024 13:35:05 UTC (2,722 KB)"
"24","Spatial-temporal-demand clustering for solving large-scale vehicle routing problems with time windows","Christoph Kerscher, Stefan Minner","Artificial Intelligence (cs.AI)","Several metaheuristics use decomposition and pruning strategies to solve large-scale instances of the vehicle routing problem (VRP). Those complexity reduction techniques often rely on simple, problem-specific rules. However, the growth in available data and advances in computer hardware enable data-based approaches that use machine learning (ML) to improve scalability of solution algorithms. We propose a decompose-route-improve (DRI) framework that groups customers using clustering. Its similarity metric incorporates customers' spatial, temporal, and demand data and is formulated to reflect the problem's objective function and constraints. The resulting sub-routing problems can independently be solved using any suitable algorithm. We apply pruned local search (LS) between solved subproblems to improve the overall solution. Pruning is based on customers' similarity information obtained in the decomposition phase. In a computational study, we parameterize and compare existing clustering algorithms and benchmark the DRI against the Hybrid Genetic Search (HGS) of Vidal et al. (2013). Results show that our data-based approach outperforms classic cluster-first, route-second approaches solely based on customers' spatial information. The newly introduced similarity metric forms separate sub-VRPs and improves the selection of LS moves in the improvement phase. Thus, the DRI scales existing metaheuristics to achieve high-quality solutions faster for large-scale VRPs by efficiently reducing complexity. Further, the DRI can be easily adapted to various solution methods and VRP characteristics, such as distribution of customer locations and demands, depot location, and different time window scenarios, making it a generalizable approach to solving routing problems.","Sat, 20 Jan 2024 06:06:01 UTC (327 KB)"
"25","Projection-based reduced order modeling and data-driven artificial viscosity closures for incompressible fluid flows","Aviral Prakash, Yongjie Jessica Zhang","Fluid Dynamics (physics.flu-dyn)","Projection-based reduced order models rely on offline-online model decomposition, where the data-based energetic spatial basis is used in the expensive offline stage to obtain equations of reduced states that evolve in time during the inexpensive online stage. The online stage requires a solution method for the dynamic evolution of the coupled system of pressure and velocity states for incompressible fluid flows. The first contribution of this article is to demonstrate the applicability of the incremental pressure correction scheme for the dynamic evolution of pressure and velocity states. The evolution of a large number of these reduced states in the online stage can be expensive. In contrast, the accuracy significantly decreases if only a few reduced states are considered while not accounting for the interactions between unresolved and resolved states. The second contribution of this article is to compare three closure model forms based on global, modal and tensor artificial viscosity approximation to account for these interactions. The unknown model parameters are determined using two calibration techniques: least squares minimization of error in energy approximation and closure term approximation. This article demonstrates that an appropriate selection of solution methods and data-driven artificial viscosity closure models is essential for consistently accurate dynamics forecasting of incompressible fluid flows.","Tue, 30 Jan 2024 19:09:36 UTC (4,311 KB)"
"26","Explainable data-driven modeling via mixture of experts: towards effective blending of grey and black-box models","Jessica Leoni, Valentina Breschi, Simone Formentin, Mara Tanelli","Machine Learning (cs.LG)","Traditional models grounded in first principles often struggle with accuracy as the system's complexity increases. Conversely, machine learning approaches, while powerful, face challenges in interpretability and in handling physical constraints. Efforts to combine these models often often stumble upon difficulties in finding a balance between accuracy and complexity. To address these issues, we propose a comprehensive framework based on a ""mixture of experts"" rationale. This approach enables the data-based fusion of diverse local models, leveraging the full potential of first-principle-based priors. Our solution allows independent training of experts, drawing on techniques from both machine learning and system identification, and it supports both collaborative and competitive learning paradigms. To enhance interpretability, we penalize abrupt variations in the expert's combination. Experimental results validate the effectiveness of our approach in producing an interpretable combination of models closely resembling the target phenomena.","Tue, 30 Jan 2024 15:53:07 UTC (4,782 KB)"
"27","Robust Functional Data Analysis for Stochastic Evolution Equations in Infinite Dimensions","Dennis Schroers","Methodology (stat.ME)","This article addresses the robust measurement of covariations in the context of solutions to stochastic evolution equations in Hilbert spaces using functional data analysis. For such equations, standard techniques for functional data based on cross-sectional covariances are often inadequate for identifying statistically relevant random drivers and detecting outliers since they overlook the interplay between cross-sectional and temporal structures. Therefore, we develop an estimation theory for the continuous quadratic covariation of the latent random driver of the equation instead of a static covariance of the observable solution process. We derive identifiability results under weak conditions, establish rates of convergence and a central limit theorem based on infill asymptotics, and provide long-time asymptotics for estimation of a static covariation of the latent driver. Applied to term structure data, our approach uncovers a fundamental alignment with scaling limits of covariations of specific short-term trading strategies, and an empirical study detects several jumps and indicates high-dimensional and time-varying covariations.","Mon, 29 Jan 2024 16:46:10 UTC (1,151 KB)"
"28","Contributing Dimension Structure of Deep Feature for Coreset Selection","Zhijing Wan, Zhixiang Wang, Yuran Wang, Zheng Wang, Hongyuan Zhu, Shin'ichi Satoh","Machine Learning (cs.LG)","Coreset selection seeks to choose a subset of crucial training samples for efficient learning. It has gained traction in deep learning, particularly with the surge in training dataset sizes. Sample selection hinges on two main aspects: a sample's representation in enhancing performance and the role of sample diversity in averting overfitting. Existing methods typically measure both the representation and diversity of data based on similarity metrics, such as L2-norm. They have capably tackled representation via distribution matching guided by the similarities of features, gradients, or other information between data. However, the results of effectively diverse sample selection are mired in sub-optimality. This is because the similarity metrics usually simply aggregate dimension similarities without acknowledging disparities among the dimensions that significantly contribute to the final similarity. As a result, they fall short of adequately capturing diversity. To address this, we propose a feature-based diversity constraint, compelling the chosen subset to exhibit maximum diversity. Our key lies in the introduction of a novel Contributing Dimension Structure (CDS) metric. Different from similarity metrics that measure the overall similarity of high-dimensional features, our CDS metric considers not only the reduction of redundancy in feature dimensions, but also the difference between dimensions that contribute significantly to the final similarity. We reveal that existing methods tend to favor samples with similar CDS, leading to a reduced variety of CDS types within the coreset and subsequently hindering model performance. In response, we enhance the performance of five classical selection methods by integrating the CDS constraint. Our experiments on three datasets demonstrate the general effectiveness of the proposed method in boosting existing methods.","Mon, 29 Jan 2024 14:47:26 UTC (1,009 KB)"
"29","Domain adaptation strategies for 3D reconstruction of the lumbar spine using real fluoroscopy data","Sascha Jecklin, Youyang Shen, Amandine Gout, Daniel Suter, Lilian Calvet, Lukas Zingg, Jennifer Straub, Nicola Alessandro Cavalcanti, Mazda Farshad, Philipp Fürnstahl, Hooman Esfandiari","Computer Vision and Pattern Recognition (cs.CV)","This study tackles key obstacles in adopting surgical navigation in orthopedic surgeries, including time, cost, radiation, and workflow integration challenges. Recently, our work X23D showed an approach for generating 3D anatomical models of the spine from only a few intraoperative fluoroscopic images. This negates the need for conventional registration-based surgical navigation by creating a direct intraoperative 3D reconstruction of the anatomy. Despite these strides, the practical application of X23D has been limited by a domain gap between synthetic training data and real intraoperative images. In response, we devised a novel data collection protocol for a paired dataset consisting of synthetic and real fluoroscopic images from the same perspectives. Utilizing this dataset, we refined our deep learning model via transfer learning, effectively bridging the domain gap between synthetic and real X-ray data. A novel style transfer mechanism also allows us to convert real X-rays to mirror the synthetic domain, enabling our in-silico-trained X23D model to achieve high accuracy in real-world settings. Our results demonstrated that the refined model can rapidly generate accurate 3D reconstructions of the entire lumbar spine from as few as three intraoperative fluoroscopic shots. It achieved an 84% F1 score, matching the accuracy of our previous synthetic data-based research. Additionally, with a computational time of only 81.1 ms, our approach provides real-time capabilities essential for surgery integration. Through examining ideal imaging setups and view angle dependencies, we've further confirmed our system's practicality and dependability in clinical settings. Our research marks a significant step forward in intraoperative 3D reconstruction, offering enhancements to surgical planning, navigation, and robotics.","Mon, 29 Jan 2024 10:22:45 UTC (14,396 KB)"
"30","Unveiling City Jam-prints of Urban Traffic based on Jam Patterns","Zeng Guanwen, Serok Nimrod, Lieberthal Efrat Blumenfeld, Duan Jinxiao, Liu Shiyan, Sui Shaobo, Li Daqing, Havlin Shlomo","Physics and Society (physics.soc-ph)","We analyze the patterns of traffic jams in urban networks of five large cities and an urban agglomeration region in China using real data based on a recently developed jam tree model. This model focuses on the way traffic jams spread through a network of streets, where the first street that becomes congested represents the bottleneck of the jam. We extended the model by integrating additional realistic jam components into the model and find that, while the locations of traffic jams can vary significantly from day to day and hour to hour, the daily distribution of the costs associated with these jams follows a consistent pattern, i.e., a power law with similar exponents. This distribution pattern appears to hold not only for a given region on different days, but also for the same hours on different days. This daily pattern of exponent values for traffic jams can be used as a fingerprint for urban traffic, i.e., jam-prints. Our findings are useful for quantifying the reliability of urban traffic system, and for improving traffic management and control.","Sat, 27 Jan 2024 15:05:17 UTC (3,478 KB)"
"31","Importance-Aware Data Augmentation for Document-Level Neural Machine Translation","Minghao Wu, Yufei Wang, George Foster, Lizhen Qu, Gholamreza Haffari","Computation and Language (cs.CL)","Document-level neural machine translation (DocNMT) aims to generate translations that are both coherent and cohesive, in contrast to its sentence-level counterpart. However, due to its longer input length and limited availability of training data, DocNMT often faces the challenge of data sparsity. To overcome this issue, we propose a novel Importance-Aware Data Augmentation (IADA) algorithm for DocNMT that augments the training data based on token importance information estimated by the norm of hidden states and training gradients. We conduct comprehensive experiments on three widely-used DocNMT benchmarks. Our empirical results show that our proposed IADA outperforms strong DocNMT baselines as well as several data augmentation approaches, with statistical significance on both sentence-level and document-level BLEU.","Sat, 27 Jan 2024 09:27:47 UTC (7,817 KB)"
"32","Depth Patterns","Annika Betken, Alexander Schnurr","Statistics Theory (math.ST)","We establish a definition of ordinal patterns for multivariate time series data based on the concept of Tukey's halfspace depth. Given the definition of these \emph{depth patterns}, we are interested in the probabilities of observing specific patterns in a time series. For this, we consider the relative frequency of depth patterns as natural estimators for their occurrence probabilities. Depending on the choice of reference distribution and the relation between reference and data distribution, we distinguish different settings that are considered separately. Within these settings we study statistical properties of ordinal pattern probabilities, establishing consistency and asymptotic normality under the assumption of weakly dependent time series data. Since our concept only depends on ordinal depth information, the resulting values are robust under small perturbations and measurement errors.","Wed, 24 Jan 2024 15:39:41 UTC (183 KB)"
"33","Improving Zero-noise Extrapolation for Quantum-gate Error Mitigation using a Noise-aware Folding Method","Leanghok Hour, Sovanmonynuth Heng, Myeongseong Go, Youngsun Han","Quantum Physics (quant-ph)","The current thousand-qubit processors mark a substantial advance in hardware. Yet, hardware limitations prevent quantum error correction (QEC), necessitating reliance on quantum error mitigation (QEM). Our paper presents a noise-aware folding method that improves Zero-Noise Extrapolation (ZNE) by estimating noiseless values from noisy results. Unlike traditional ZNE methods, which assume a uniform error distribution, our method redistributes the noise using calibration data based on hardware noise models. By employing noise-adaptive compilation and optimizing the qubit mappings, our approach enhances the ZNE accuracy of various quantum computing models. Recalibrating the noise amplification to address the inherent error variations, promises higher precision and reliability in quantum computations. This paper highlights the uniqueness of our method, summarizes noise accumulation, presents the scaling algorithm, and compares the reliability of our method with those of existing models using linear fit extrapolation. Relative to the existing folding methods, our method achieved a 35% improvement on quantum computer simulators and a 26% improvement on real quantum computers compared to existing folding methods, demonstrating the effectiveness of our proposed approach.","Tue, 23 Jan 2024 05:36:40 UTC (1,733 KB)"
"34","FinLLMs: A Framework for Financial Reasoning Dataset Generation with Large Language Models","Ziqiang Yuan, Kaiyuan Wang, Shoutai Zhu, Ye Yuan, Jingya Zhou, Yanlin Zhu, Wenqi Wei","Artificial Intelligence (cs.AI)","Large Language models (LLMs) usually rely on extensive training datasets. In the financial domain, creating numerical reasoning datasets that include a mix of tables and long text often involves substantial manual annotation expenses. To address the limited data resources and reduce the annotation cost, we introduce FinLLMs, a method for generating financial question-answering data based on common financial formulas using Large Language Models. First, we compile a list of common financial formulas and construct a graph based on the variables these formulas employ. We then augment the formula set by combining those that share identical variables as new elements. Specifically, we explore formulas obtained by manual annotation and merge those formulas with shared variables by traversing the constructed graph. Finally, utilizing GPT-3.5, we generate financial question-answering data that encompasses both tabular information and long textual content, building on the collected formula set. Our experiments demonstrate that synthetic data generated by FinLLMs effectively enhances the performance of several large-scale numerical reasoning models in the financial domain, outperforming two established benchmark financial question-answering datasets.","Fri, 19 Jan 2024 15:09:39 UTC (3,580 KB)"
"35","MorpheusNet: Resource efficient sleep stage classifier for embedded on-line systems","Ali Kavoosi, Morgan P. Mitchell, Raveen Kariyawasam, John E. Fleming, Penny Lewis, Heidi Johansen-Berg, Hayriye Cagnan, Timothy Denison","Signal Processing (eess.SP)","Sleep Stage Classification (SSC) is a labor-intensive task, requiring experts to examine hours of electrophysiological recordings for manual classification. This is a limiting factor when it comes to leveraging sleep stages for therapeutic purposes. With increasing affordability and expansion of wearable devices, automating SSC may enable deployment of sleep-based therapies at scale. Deep Learning has gained increasing attention as a potential method to automate this process. Previous research has shown accuracy comparable to manual expert scores. However, previous approaches require sizable amount of memory and computational resources. This constrains the ability to classify in real time and deploy models on the edge. To address this gap, we aim to provide a model capable of predicting sleep stages in real-time, without requiring access to external computational sources (e.g., mobile phone, cloud). The algorithm is power efficient to enable use on embedded battery powered systems. Our compact sleep stage classifier can be deployed on most off-the-shelf microcontrollers (MCU) with constrained hardware settings. This is due to the memory footprint of our approach requiring significantly fewer operations. The model was tested on three publicly available data bases and achieved performance comparable to the state of the art, whilst reducing model complexity by orders of magnitude (up to 280 times smaller compared to state of the art). We further optimized the model with quantization of parameters to 8 bits with only an average drop of 0.95% in accuracy. When implemented in firmware, the quantized model achieves a latency of 1.6 seconds on an Arm CortexM4 processor, allowing its use for on-line SSC-based therapies.","Sun, 14 Jan 2024 17:52:08 UTC (998 KB)"
"36","Selecting Subsets of Source Data for Transfer Learning with Applications in Metal Additive Manufacturing","Yifan Tang, M. Rahmani Dehaghani, Pouyan Sajadi, G. Gary Wang","Machine Learning (cs.LG)","Considering data insufficiency in metal additive manufacturing (AM), transfer learning (TL) has been adopted to extract knowledge from source domains (e.g., completed printings) to improve the modeling performance in target domains (e.g., new printings). Current applications use all accessible source data directly in TL with no regard to the similarity between source and target data. This paper proposes a systematic method to find appropriate subsets of source data based on similarities between the source and target datasets for a given set of limited target domain data. Such similarity is characterized by the spatial and model distance metrics. A Pareto frontier-based source data selection method is developed, where the source data located on the Pareto frontier defined by two similarity distance metrics are selected iteratively. The method is integrated into an instance-based TL method (decision tree regression model) and a model-based TL method (fine-tuned artificial neural network). Both models are then tested on several regression tasks in metal AM. Comparison results demonstrate that 1) the source data selection method is general and supports integration with various TL methods and distance metrics, 2) compared with using all source data, the proposed method can find a small subset of source data from the same domain with better TL performance in metal AM regression tasks involving different processes and machines, and 3) when multiple source domains exist, the source data selection method could find the subset from one source domain to obtain comparable or better TL performance than the model constructed using data from all source domains.","Tue, 16 Jan 2024 00:14:37 UTC (891 KB)"
"37","Automatic extraction and 3D reconstruction of split wire from point cloud data based on improved DPC algorithm","Jia Cheng","Computer Vision and Pattern Recognition (cs.CV)","In order to solve the problem of point cloud data splitting improved by DPC algorithm, a research on automatic separation and 3D reconstruction of point cloud data split lines is proposed. First, the relative coordinates of each point in the cloud point are calculated. Second, it is planned to develop a relative ensemble-based DPC swarm algorithm for analyzing the number of separation lines to determine all parts in the cloud content. Finally, fit each separator using the least squares method. iron. The cloud point of the resulting split subconductors has a clear demarcation line, and the distance between adjacent split subconductors is 0.45 m, divided by the four vertices of the square.","Fri, 10 Nov 2023 05:29:25 UTC (381 KB)"
"38","Survey of Learning Approaches for Robotic In-Hand Manipulation","Abraham Itzhak Weinberg, Alon Shirizly, Osher Azulay, Avishai Sintov","Robotics (cs.RO)","Human dexterity is an invaluable capability for precise manipulation of objects in complex tasks. The capability of robots to similarly grasp and perform in-hand manipulation of objects is critical for their use in the ever changing human environment, and for their ability to replace manpower. In recent decades, significant effort has been put in order to enable in-hand manipulation capabilities to robotic systems. Initial robotic manipulators followed carefully programmed paths, while later attempts provided a solution based on analytical modeling of motion and contact. However, these have failed to provide practical solutions due to inability to cope with complex environments and uncertainties. Therefore, the effort has shifted to learning-based approaches where data is collected from the real world or through a simulation, during repeated attempts to complete various tasks. The vast majority of learning approaches focused on learning data-based models that describe the system to some extent or Reinforcement Learning (RL). RL, in particular, has seen growing interest due to the remarkable ability to generate solutions to problems with minimal human guidance. In this survey paper, we track the developments of learning approaches for in-hand manipulations and, explore the challenges and opportunities. This survey is designed both as an introduction for novices in the field with a glossary of terms as well as a guide of novel advances for advanced practitioners.","Mon, 15 Jan 2024 19:07:37 UTC (1,963 KB)"
"39","Enforcing contraction via data","Zhongjie Hu, Claudio De Persis, Pietro Tesi","Systems and Control (eess.SY)","We present data-based conditions for enforcing contractivity via feedback control and obtain desired asymptotic properties of the closed-loop system. We focus on unknown nonlinear control systems whose vector fields are expressible via a dictionary of functions and derive data-dependent semidefinite programs whose solution returns the controller that guarantees contractivity. When data are perturbed by disturbances that are linear combination of sinusoids of known frequencies (but unknown amplitude and phase) and constants, we remarkably obtain conditions for contractivity that do not depend on the magnitude of the disturbances, with imaginable positive consequences for the synthesis of the controller. Finally, we show how to design from data an integral controller for nonlinear systems that achieves constant reference tracking and constant disturbance rejection.","Mon, 15 Jan 2024 16:46:04 UTC (140 KB)"
"40","Robust Data-Driven Predictive Control for Unknown Linear Time-Invariant Systems","Kaijian Hu, Tao Liu","Systems and Control (eess.SY)","This paper presents a new robust data-driven predictive control scheme for unknown linear time-invariant systems by using input-state-output or input-output data based on whether the state is measurable. To remove the need for the persistently exciting (PE) condition of a sufficiently high order on pre-collected data, a set containing all systems capable of generating such data is constructed. Then, at each time step, an upper bound of a given objective function is derived for all systems in the set, and a feedback controller is designed to minimize this bound. The optimal control gain at each time step is determined by solving a set of linear matrix inequalities. We prove that if the synthesis problem is feasible at the initial time step, it remains feasible for all future time steps. Unlike current data-driven predictive control schemes based on behavioral system theory, our approach requires less stringent conditions for the pre-collected data, facilitating easier implementation. Further, the proposed predictive control scheme features an infinite prediction horizon, potentially resulting in superior overall control performance compared to existing methods with finite prediction horizons. The effectiveness of our proposed methods is demonstrated through application to an unknown and unstable batch reactor.","Sun, 14 Jan 2024 07:42:57 UTC (172 KB)"
"41","Multicriteria decision support employing adaptive prediction in a tensor-based feature representation","Betania Silva Carneiro Campello, Leonardo Tomazeli Duarte, João Marcos Travassos Romano","Machine Learning (cs.LG)","Multicriteria decision analysis (MCDA) is a widely used tool to support decisions in which a set of alternatives should be ranked or classified based on multiple criteria. Recent studies in MCDA have shown the relevance of considering not only current evaluations of each criterion but also past data. Past-data-based approaches carry new challenges, especially in time-varying environments. This study deals with this challenge via essential tools of signal processing, such as tensorial representations and adaptive prediction. More specifically, we structure the criteria' past data as a tensor and, by applying adaptive prediction, we compose signals with these prediction values of the criteria. Besides, we transform the prediction in the time domain into a most favorable decision making domain, called the feature domain. We present a novel extension of the MCDA method PROMETHEE II, aimed at addressing the tensor in the feature domain to obtain a ranking of alternatives. Numerical experiments were performed using real-world time series, and our approach is compared with other existing strategies. The results highlight the relevance and efficiency of our proposal, especially for nonstationary time series.","Fri, 12 Jan 2024 19:46:29 UTC (706 KB)"
"42","A proposal to increase data utility on Global Differential Privacy data based on data use predictions","Henry C. Nunes, Marlon P. da Silva, Charles V. Neu, Avelino F. Zorzo","Cryptography and Security (cs.CR)","This paper presents ongoing research focused on improving the utility of data protected by Global Differential Privacy(DP) in the scenario of summary statistics. Our approach is based on predictions on how an analyst will use statistics released under DP protection, so that a developer can optimise data utility on further usage of the data in the privacy budget allocation. This novel approach can potentially improve the utility of data without compromising privacy constraints. We also propose a metric that can be used by the developer to optimise the budget allocation process.","Fri, 12 Jan 2024 14:34:30 UTC (168 KB)"
"43","Secrets of RLHF in Large Language Models Part II: Reward Modeling","Binghai Wang, Rui Zheng, Lu Chen, Yan Liu, Shihan Dou, Caishuang Huang, Wei Shen, Senjie Jin, Enyu Zhou, Chenyu Shi, Songyang Gao, Nuo Xu, Yuhao Zhou, Xiaoran Fan, Zhiheng Xi, Jun Zhao, Xiao Wang, Tao Ji, Hang Yan, Lixing Shen, Zhan Chen, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang","Artificial Intelligence (cs.AI)","Reinforcement Learning from Human Feedback (RLHF) has become a crucial technology for aligning language models with human values and intentions, enabling models to produce more helpful and harmless responses. Reward models are trained as proxies for human preferences to drive reinforcement learning optimization. While reward models are often considered central to achieving high performance, they face the following challenges in practical applications: (1) Incorrect and ambiguous preference pairs in the dataset may hinder the reward model from accurately capturing human intent. (2) Reward models trained on data from a specific distribution often struggle to generalize to examples outside that distribution and are not suitable for iterative RLHF training. In this report, we attempt to address these two issues. (1) From a data perspective, we propose a method to measure the strength of preferences within the data, based on a voting mechanism of multiple reward models. Experimental results confirm that data with varying preference strengths have different impacts on reward model performance. We introduce a series of novel methods to mitigate the influence of incorrect and ambiguous preferences in the dataset and fully leverage high-quality preference data. (2) From an algorithmic standpoint, we introduce contrastive learning to enhance the ability of reward models to distinguish between chosen and rejected responses, thereby improving model generalization. Furthermore, we employ meta-learning to enable the reward model to maintain the ability to differentiate subtle differences in out-of-distribution samples, and this approach can be utilized for iterative RLHF optimization.","Thu, 11 Jan 2024 17:56:59 UTC (10,119 KB)[v2] Fri, 12 Jan 2024 09:46:10 UTC (10,091 KB)"
"44","Generation of BIM data based on the automatic detection, identification and localization of lamps in buildings","Francisco Troncoso-Pastoriza, Pablo Eguía-Oller, Rebeca P. Díaz-Redondo, Enrique Granada-Álvarez","Computer Vision and Pattern Recognition (cs.CV)","In this paper we introduce a method that supports the detection, identification and localization of lamps in a building, with the main goal of automatically feeding its energy model by means of Building Information Modeling (BIM) methods. The proposed method, thus, provides useful information to apply energy-saving strategies to reduce energy consumption in the building sector through the correct management of the lighting infrastructure. Based on the unique geometry and brightness of lamps and the use of only greyscale images, our methodology is able to obtain accurate results despite its low computational needs, resulting in near-real-time processing. The main novelty is that the focus of the candidate search is not over the entire image but instead only on a limited region that summarizes the specific characteristics of the lamp. The information obtained from our approach was used on the Green Building XML Schema to illustrate the automatic generation of BIM data from the results of the algorithm.","Mon, 18 Dec 2023 16:54:48 UTC (14,969 KB)"
"45","Unifying Graph Contrastive Learning via Graph Message Augmentation","Ziyan Zhang, Bo Jiang, Jin Tang, Bin Luo","Machine Learning (cs.LG)","Graph contrastive learning is usually performed by first conducting Graph Data Augmentation (GDA) and then employing a contrastive learning pipeline to train GNNs. As we know that GDA is an important issue for graph contrastive learning. Various GDAs have been developed recently which mainly involve dropping or perturbing edges, nodes, node attributes and edge attributes. However, to our knowledge, it still lacks a universal and effective augmentor that is suitable for different types of graph data. To address this issue, in this paper, we first introduce the graph message representation of graph data. Based on it, we then propose a novel Graph Message Augmentation (GMA), a universal scheme for reformulating many existing GDAs. The proposed unified GMA not only gives a new perspective to understand many existing GDAs but also provides a universal and more effective graph data augmentation for graph self-supervised learning tasks. Moreover, GMA introduces an easy way to implement the mixup augmentor which is natural for images but usually challengeable for graphs. Based on the proposed GMA, we then propose a unified graph contrastive learning, termed Graph Message Contrastive Learning (GMCL), that employs attribution-guided universal GMA for graph contrastive learning. Experiments on many graph learning tasks demonstrate the effectiveness and benefits of the proposed GMA and GMCL approaches.","Mon, 8 Jan 2024 02:49:16 UTC (819 KB)"
"46","TSGAN: An Optical-to-SAR Dual Conditional GAN for Optical based SAR Temporal Shifting","Moien Rangzan, Sara Attarchi, Richard Gloaguen, Seyed Kazem Alavipanah","Computer Vision and Pattern Recognition (cs.CV)","In contrast to the well-investigated field of SAR-to-Optical translation, this study explores the lesser-investigated domain of Optical-to-SAR translation, a challenging field due to the ill-posed nature of this translation. The complexity arises as a single optical data can have multiple SAR representations based on the SAR viewing geometry. We propose a novel approach, termed SAR Temporal Shifting, which inputs an optical data from the desired timestamp along with a SAR data from a different temporal point but with a consistent viewing geometry as the expected SAR data, both complemented with a change map of optical data during the intervening period. This model modifies the SAR data based on the changes observed in optical data to generate the SAR data for the desired timestamp. Our model, a dual conditional Generative Adversarial Network (GAN), named Temporal Shifting GAN (TSGAN), incorporates a siamese encoder in both the Generator and the Discriminator. To prevent the model from overfitting on the input SAR data, we employed a change weighted loss function. Our approach surpasses traditional translation methods by eliminating the GAN's fiction phenomenon, particularly in unchanged regions, resulting in higher SSIM and PSNR in these areas. Additionally, modifications to the Pix2Pix architecture and the inclusion of attention mechanisms have enhanced the model's performance on all regions of the data. This research paves the way for leveraging legacy optical datasets, the most abundant and longstanding source of Earth imagery data, extending their use to SAR domains and temporal analyses. To foster further research, we provide the code, datasets used in our study, and a framework for generating paired SAR-Optical datasets for new regions of interest. These resources are available on this http URL","Sun, 31 Dec 2023 09:38:53 UTC (5,716 KB)[v2] Thu, 4 Jan 2024 09:43:33 UTC (5,716 KB)"
"47","Designer Pair Statistics of Disordered Many-Particle Systems with Novel Properties","Haina Wang, Salvatore Torquato","Soft Condensed Matter (cond-mat.soft)","Knowledge of exact analytical functional forms for the pair correlation function $g_2(r)$ and its corresponding structure factor $S(k)$ of disordered many-particle systems is limited. For fundamental and practical reasons, it is highly desirable to add to the existing data base of analytical functional forms for such pair statistics. Here, we design a plethora of such pair functions in direct and Fourier spaces across the first three Euclidean space dimensions that are realizable by diverse many-particle systems with varying degrees of correlated disorder across length scales, spanning a wide spectrum of hyperuniform, typical nonhyperuniform and antihyperuniform ones. This is accomplished by utilizing an efficient inverse algorithm that determines equilibrium states with up to pair interactions at positive temperature that precisely match targeted forms for both $g_2(r)$ and $S(k)$. Among other results, we realize an example with the strongest hyperuniform property among known positive-temperature equilibrium states, critical-point systems (implying unusual 1D systems with phase transitions) that are not in the Ising universality class, systems that attain self-similar pair statistics under Fourier transformation, and an experimentally feasible polymer model. We show that our pair functions enable one to achieve systems with a wide range of translational order and self-diffusion coefficients $\cal D$, which are inversely related to one another. One can design other realizable pair statistics via linear combinations of our functions or by applying our inverse procedure to other desirable functional forms. Our approach facilitates the inverse design of materials with desirable physical and chemical properties by tuning their pair statistics.","Fri, 29 Dec 2023 23:43:40 UTC (4,325 KB)"
"48","Research on the Laws of Multimodal Perception and Cognition from a Cross-cultural Perspective -- Taking Overseas Chinese Gardens as an Example","Ran Chen, Xueqi Yao, Jing Zhao, Shuhan Xu, Sirui Zhang, Yijun Mao","Artificial Intelligence (cs.AI)","This study aims to explore the complex relationship between perceptual and cognitive interactions in multimodal data analysis,with a specific emphasis on spatial experience design in overseas Chinese gardens. It is found that evaluation content and images on social media can reflect individuals' concerns and sentiment responses, providing a rich data base for cognitive research that contains both sentimental and image-based cognitive information. Leveraging deep learning techniques, we analyze textual and visual data from social media, thereby unveiling the relationship between people's perceptions and sentiment cognition within the context of overseas Chinese gardens. In addition, our study introduces a multi-agent system (MAS)alongside AI agents. Each agent explores the laws of aesthetic cognition through chat scene simulation combined with web search. This study goes beyond the traditional approach of translating perceptions into sentiment scores, allowing for an extension of the research methodology in terms of directly analyzing texts and digging deeper into opinion data. This study provides new perspectives for understanding aesthetic experience and its impact on architecture and landscape design across diverse cultural contexts, which is an essential contribution to the field of cultural communication and aesthetic understanding.","Fri, 29 Dec 2023 15:13:23 UTC (2,856 KB)"
"49","The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems: A Scoping Survey","Dhruv Dhamani, Mary Lou Maher","Software Engineering (cs.SE)","This scoping survey focuses on our current understanding of the design space for task-oriented LLM systems and elaborates on definitions and relationships among the available design parameters. The paper begins by defining a minimal task-oriented LLM system and exploring the design space of such systems through a thought experiment contemplating the performance of diverse LLM system configurations (involving single LLMs, single LLM-based agents, and multiple LLM-based agent systems) on a complex software development task and hypothesizes the results. We discuss a pattern in our results and formulate them into three conjectures. While these conjectures may be partly based on faulty assumptions, they provide a starting point for future research. The paper then surveys a select few design parameters: covering and organizing research in LLM augmentation, prompting techniques, and uncertainty estimation, and discussing their significance. The paper notes the lack of focus on computational and energy efficiency in evaluating research in these areas. Our survey findings provide a basis for developing the concept of linear and non-linear contexts, which we define and use to enable an agent-centric projection of prompting techniques providing a lens through which prompting techniques can be viewed as multi-agent systems. The paper discusses the implications of this lens, for the cross-pollination of research between LLM prompting and LLM-based multi-agent systems; and also, for the generation of synthetic training data based on existing prompting techniques in research. In all, the scoping survey presents seven conjectures that can help guide future research efforts.","Fri, 29 Dec 2023 13:35:20 UTC (708 KB)"
"50","PG-LBO: Enhancing High-Dimensional Bayesian Optimization with Pseudo-Label and Gaussian Process Guidance","Taicai Chen, Yue Duan, Dong Li, Lei Qi, Yinghuan Shi, Yang Gao","Machine Learning (cs.LG)","Variational Autoencoder based Bayesian Optimization (VAE-BO) has demonstrated its excellent performance in addressing high-dimensional structured optimization problems. However, current mainstream methods overlook the potential of utilizing a pool of unlabeled data to construct the latent space, while only concentrating on designing sophisticated models to leverage the labeled data. Despite their effective usage of labeled data, these methods often require extra network structures, additional procedure, resulting in computational inefficiency. To address this issue, we propose a novel method to effectively utilize unlabeled data with the guidance of labeled data. Specifically, we tailor the pseudo-labeling technique from semi-supervised learning to explicitly reveal the relative magnitudes of optimization objective values hidden within the unlabeled data. Based on this technique, we assign appropriate training weights to unlabeled data to enhance the construction of a discriminative latent space. Furthermore, we treat the VAE encoder and the Gaussian Process (GP) in Bayesian optimization as a unified deep kernel learning process, allowing the direct utilization of labeled data, which we term as Gaussian Process guidance. This directly and effectively integrates the goal of improving GP accuracy into the VAE training, thereby guiding the construction of the latent space. The extensive experiments demonstrate that our proposed method outperforms existing VAE-BO algorithms in various optimization scenarios. Our code will be published at this https URL.","Thu, 28 Dec 2023 11:57:58 UTC (1,408 KB)"
"51","Acoustic emission data based modelling of fracture of glassy polymer","Subrat Senapati, Anuradha Banerjee, R. Rajesh","Statistical Mechanics (cond-mat.stat-mech)","Acoustic emission (AE) activity data resulting from the fracture processes of brittle materials is valuable real time information regarding the evolving state of damage in the material. Here, through a combined experimental and computational study we explore the possibility of utilising the statistical signatures of AE activity data for characterisation of disorder parameter in simulation of tensile fracture of epoxy based polymer. For simulations we use a square random spring network model with quasi-brittle spring behaviour and a normally distributed failure strain threshold. We show that the disorder characteristics while have marginal effect on the power law exponent of the avalanche size distribution, are strongly correlated with the waiting time interval between consecutive record breaking avalanches as well as the total number of records. This sensitivity to disorder is exploited in estimating the disorder parameter suitable for the experiments on tensile failure of epoxy based polymer. The disorder parameter is estimated assuming equivalence between the amplitude distribution of AE data and avalanche size distribution of the simulations. The chosen disorder parameter is shown to well reproduce the failure characteristics in terms of the peak load of the macroscopic response, the power-law behaviour with avalanche dominated fracture type as well as realistic fracture paths.","Thu, 28 Dec 2023 09:03:05 UTC (1,804 KB)"
"52","Transfer and Alignment Network for Generalized Category Discovery","Wenbin An, Feng Tian, Wenkai Shi, Yan Chen, Yaqiang Wu, Qianying Wang, Ping Chen","Computation and Language (cs.CL)","Generalized Category Discovery is a crucial real-world task. Despite the improved performance on known categories, current methods perform poorly on novel categories. We attribute the poor performance to two reasons: biased knowledge transfer between labeled and unlabeled data and noisy representation learning on the unlabeled data. To mitigate these two issues, we propose a Transfer and Alignment Network (TAN), which incorporates two knowledge transfer mechanisms to calibrate the biased knowledge and two feature alignment mechanisms to learn discriminative features. Specifically, we model different categories with prototypes and transfer the prototypes in labeled data to correct model bias towards known categories. On the one hand, we pull instances with known categories in unlabeled data closer to these prototypes to form more compact clusters and avoid boundary overlap between known and novel categories. On the other hand, we use these prototypes to calibrate noisy prototypes estimated from unlabeled data based on category similarities, which allows for more accurate estimation of prototypes for novel categories that can be used as reliable learning targets later. After knowledge transfer, we further propose two feature alignment mechanisms to acquire both instance- and category-level knowledge from unlabeled data by aligning instance features with both augmented features and the calibrated prototypes, which can boost model performance on both known and novel categories with less noise. Experiments on three benchmark datasets show that our model outperforms SOTA methods, especially on novel categories. Theoretical analysis is provided for an in-depth understanding of our model in general. Our code and data are available at this https URL.","Wed, 27 Dec 2023 08:35:47 UTC (1,453 KB)"
"53","Filtered data based estimators for stochastic processes driven by colored noise","Grigorios A. Pavliotis, Sebastian Reich, Andrea Zanoni","Numerical Analysis (math.NA)","We consider the problem of estimating unknown parameters in stochastic differential equations driven by colored noise, which we model as a sequence of Gaussian stationary processes with decreasing correlation time. We aim to infer parameters in the limit equation, driven by white noise, given observations of the colored noise dynamics. We consider both the maximum likelihood and the stochastic gradient descent in continuous time estimators, and we propose to modify them by including filtered data. We provide a convergence analysis for our estimators showing their asymptotic unbiasedness in a general setting and asymptotic normality under a simplified scenario.","Tue, 26 Dec 2023 10:02:10 UTC (2,613 KB)[v2] Mon, 22 Jan 2024 19:52:04 UTC (2,732 KB)"
"54","From masses and radii of neutron stars to EOS of nuclear matter through neural network","Zehan Wu, Dehua Wen","Nuclear Theory (nucl-th)","The equation of state (EOS) of dense nuclear matter is a key factor to determine the internal structure and properties of neutron stars. However, the EOS of high-density nuclear matter has great uncertainty mainly because the terrestrial nuclear experiments cannot reproduce matter as dense as that in the inner core of a neutron star. Fortunately, continuous improvements in astronomical observations of neutron stars provide the opportunity to inversely constrain the EOS of high-density nuclear matter. A number of methods have been proposed to implement this inverse constraint, such as the Bayesian analysis algorithm, the Lindblom's approach, and so on. Neural network algorithm is an effective new method developed in recent years. By employing a set of isospin-dependent parametric EOSs as the training sample of neural network algorithm, we set up an effective way to reconstruct the EOS with relative accuracy through a few mass-radius data. Based on the obtained neural network algorithms and according to the NICER observations on masses and radii of neutron stars with assumed precision, we get the inversely constrained EOS and further calculate the corresponding macroscopic properties of the neutron star. The results are basically consistent with the constraint on EOS from the Huth $et~ al.$ based on Bayesian analysis. Moreover, the results show that even though the neural network algorithm was obtained by using the finite parameterized EOS as the training set, it is valid for any rational parameter combination of the parameterized EOS model.","Mon, 25 Dec 2023 06:50:01 UTC (106 KB)"
"55","Harnessing the Final Control Error for Optimal Data-Driven Predictive Control","Alessandro Chiuso, Marco Fabris, Valentina Breschi, Simone Formentin","Systems and Control (eess.SY)","Model Predictive Control (MPC) is a powerful method for complex system regulation, but its reliance on accurate models poses many limitations in real-world applications. Data-driven predictive control (DDPC) offers a valid alternative, eliminating the need for model identification. However, it may falter in the presence of noisy data. In response, in this work, we present a unified stochastic framework for direct DDPC where control actions are obtained by optimizing the Final Control Error, directly computed from available data only, that automatically weighs the impact of uncertainty on the control objective. Our approach generalizes existing DDPC methods, like regularized Data-enabled Predictive Control (DeePC) and $\gamma$-DDPC, and thus provides a path toward noise-tolerant data-based control, with rigorous optimality guarantees. The theoretical investigation is complemented by a series of numerical case studies, revealing that the proposed method consistently outperforms or, at worst, matches existing techniques without requiring tuning regularization parameters as methods do.","Fri, 22 Dec 2023 16:00:42 UTC (1,036 KB)"
"56","A Novel ML-driven Test Case Selection Approach for Enhancing the Performance of Grammatical Evolution","Krishn Kumar Gupt, Meghana Kshirsagar, Douglas Mota Dias, Joseph P. Sullivan, Conor Ryan","Neural and Evolutionary Computing (cs.NE)","Computational cost in metaheuristics such as Evolutionary Algorithms (EAs) is often a major concern, particularly with their ability to scale. In data-based training, traditional EAs typically use a significant portion, if not all, of the dataset for model training and fitness evaluation in each generation. This makes EAs suffer from high computational costs incurred during the fitness evaluation of the population, particularly when working with large datasets. To mitigate this issue, we propose a Machine Learning (ML)-driven Distance-based Selection (DBS) algorithm that reduces the fitness evaluation time by optimizing test cases. We test our algorithm by applying it to 24 benchmark problems from Symbolic Regression (SR) and digital circuit domains and then using Grammatical Evolution (GE) to train models using the reduced dataset. We use GE to test DBS on SR and produce a system flexible enough to test it on digital circuit problems further. The quality of the solutions is tested and compared against the conventional training method to measure the coverage of training data selected using DBS, i.e., how well the subset matches the statistical properties of the entire dataset. Moreover, the effect of optimized training data on run time and the effective size of the evolved solutions is analyzed. Experimental and statistical evaluations of the results show our method empowered GE to yield superior or comparable solutions to the baseline (using the full datasets) with smaller sizes and demonstrates computational efficiency in terms of speed.","Thu, 21 Dec 2023 22:21:02 UTC (5,457 KB)"
"57","Modelling of Networked Measuring Systems -- From White-Box Models to Data Based Approaches","Klaus-Dieter Sommer (1), Peter Harris (2), Sascha Eichstädt (3), Roland Füssl (1), Tanja Dorst (4), Andreas Schütze (4), Michael Heizmann (5), Nadine Schiering (6), Andreas Maier (7), Yuhui Luo (2), Christos Tachtatzis (8), Ivan Andonovic (8), Gordon Gourlay (9) ((1) Technische Universitaet Ilmenau, Germany, (2) National Physical Laboratory, Teddington, United Kingdom, (3) Physikalisch-Technische Bundesanstalt, Braunschweig and Berlin, Germany, (4) ZeMA - Zentrum für Mechatronik und Automatisierungstechnik gGmbH, Saarbrücken, Germany, (5) Karlsruhe Institute of Technology, Germany, (6) Centre for Measurement and Calibration, Wolfen, Germany, (7) Friedrich-Alexander-University of Erlangen-Nuremberg, Germany, (8) Department of Electronic and Electrical Engineering, University of Strathclyde, UK, (9) Advanced Forming Research Centre, University of Strathclyde, UK)","Systems and Control (eess.SY)","Mathematical modelling is at the core of metrology as it transforms raw measured data into useful measurement results. A model captures the relationship between the measurand and all relevant quantities on which the measurand depends, and is used to design measuring systems, analyse measured data, make inferences and predictions, and is the basis for evaluating measurement uncertainties. Traditional modelling approaches are typically analytical, for example, based on principles of physics. But with the increasing use of digital technologies, large sensor networks and powerful computing hardware, these traditional approaches are being replaced more and more by data-driven methods. This paradigm shift holds true in particular for the digital future of measurement in all spheres of our lives and the environment, where data provided by large and complex interconnected systems of sensors are to be analysed. Additionally, there is a requirement for existing guidelines and standards in metrology to take the paradigm shift into account. In this paper we lay the foundation for the development from traditional to data-driven modelling approaches. We identify key aspects from traditional modelling approaches and discuss their transformation to data-driven modelling.","Thu, 21 Dec 2023 11:25:45 UTC (2,131 KB)"
"58","Learning and Forgetting Unsafe Examples in Large Language Models","Jiachen Zhao, Zhun Deng, David Madras, James Zou, Mengye Ren","Computation and Language (cs.CL)","As the number of large language models (LLMs) released to the public grows, there is a pressing need to understand the safety implications associated with these models learning from third-party custom finetuning data. We explore the behavior of LLMs finetuned on noisy custom data containing unsafe content, represented by datasets that contain biases, toxicity, and harmfulness, finding that while aligned LLMs can readily learn this unsafe content, they also tend to forget it more significantly than other examples when subsequently finetuned on safer content. Drawing inspiration from the discrepancies in forgetting, we introduce the ""ForgetFilter"" algorithm, which filters unsafe data based on how strong the model's forgetting signal is for that data. We demonstrate that the ForgetFilter algorithm ensures safety in customized finetuning without compromising downstream task performance, unlike sequential safety finetuning. ForgetFilter outperforms alternative strategies like replay and moral self-correction in curbing LLMs' ability to assimilate unsafe content during custom finetuning, e.g. 75% lower than not applying any safety measures and 62% lower than using self-correction in toxicity score.","Wed, 20 Dec 2023 03:18:50 UTC (389 KB)"
"59","Single-pixel 3D imaging based on fusion temporal data of single photon detector and millimeter-wave radar","Tingqin Lai, Xiaolin Liang, Yi Zhu, Xinyi Wu, Lianye Liao, Xuelin Yuan, Ping Su, Shihai Sun","Computer Vision and Pattern Recognition (cs.CV)","Recently, there has been increased attention towards 3D imaging using single-pixel single-photon detection (also known as temporal data) due to its potential advantages in terms of cost and power efficiency. However, to eliminate the symmetry blur in the reconstructed images, a fixed background is required. This paper proposes a fusion-data-based 3D imaging method that utilizes a single-pixel single-photon detector and a millimeter-wave radar to capture temporal histograms of a scene from multiple perspectives. Subsequently, the 3D information can be reconstructed from the one-dimensional fusion temporal data by using Artificial Neural Network (ANN). Both the simulation and experimental results demonstrate that our fusion method effectively eliminates symmetry blur and improves the quality of the reconstructed images.","Fri, 20 Oct 2023 13:03:48 UTC (24,170 KB)"
"60","Constraints on Phase Transitions in Neutron Star Matter","Len Brandes, Wolfram Weise","Nuclear Theory (nucl-th)","Recent inference results of the sound velocity in the cores of neutron stars are summarized. Implications for the equation of state and the phase structure of highly compressed baryonic matter are discussed. In view of the strong constraints imposed by the heaviest known pulsars, the equation of state must be very stiff in order to ensure the stability of these extreme objects. This required stiffness limits the possible appearance of phase transitions in neutron star cores. For example, a Bayes factor analysis quantifies strong evidence for squared sound velocities $c_s^2 > 0.1$ in the cores of 2.1 solar-mass and lighter neutron stars. Only weak first-order phase transitions with a small phase coexistence density range $\Delta\rho/\rho < 0.2$ (at the 68\% level) in a Maxwell construction still turn out to be possible within neutron stars. The central baryon densities in even the heaviest neutron stars do not exceed five times the density of normal nuclear matter. In view of these data-based constraints, much discussed issues such as the quest for a phase transition towards restored chiral symmetry, and the active degrees of freedom in cold and dense baryonic matter, are reexamined.","Tue, 19 Dec 2023 08:29:18 UTC (6,721 KB)[v2] Thu, 11 Jan 2024 02:01:48 UTC (3,809 KB)[v3] Mon, 22 Jan 2024 03:03:18 UTC (10,716 KB)"
"61","Data-based Model Identification of the Hypothalamus-Pituitary-Thyroid Complex","Clara Horvath, Andreas Körner, Corinna Modiz","Tissues and Organs (q-bio.TO)","The thyroid gland, in conjunction with the pituitary and the hypothalamus, forms a regulated system due to their mutual influence through released hormones. The equilibrium point of this system, commonly referred to as the ""set point"", is individually determined. This means that determining the correct amount of medication to be administered to patients with hypothyroidism requires several treatment appointments creating an extended treatment process. Because the dynamics of the system have not yet been fully explored, mathematical models are needed to simulate the mutual influence of the respective hormones as well as their course over time. These models enable a deeper understanding of the functionality in the context of data measurements. Therefore, two existing time-dependent mathematical models are used and further analyzed to replicate this overall influence of disparate systems. Both are based on a system of two differential equations modelling the interacting hormones. The parameters of the two models are identified according to different calibration approaches by means of patient data collected in a retrospective study in collaboration with the Medical University of Vienna. The hormonal course in the time domain as well as equilibrium curves including the set-point are then simulated and analyzed with respect to the normalized mean squared error. These calibrated systems allow a more profound insight into the functionality of the formed complex.","Mon, 18 Dec 2023 13:22:47 UTC (580 KB)"
"62","A dependent circular-linear model for multivariate biomechanical data: Ilizarov ring fixator study","Priyanka Nagar, Andriette Bekker, Mohammad Arashi, Cor-Jacques Kat, Annette-Christi Barnard","Applications (stat.AP)","Biomechanical and orthopaedic studies frequently encounter complex datasets that encompass both circular and linear variables. In most cases the circular and linear variables are (i) considered in isolation with dependency between variables neglected and (ii) the cyclicity of the circular variables disregarded resulting in erroneous decision making. Given the inherent characteristics of circular variables, it is imperative to adopt methods that integrate directional statistics to achieve precise modelling. This paper is motivated by the modelling of biomechanical data, i.e., the fracture displacements, that is used as a measure in external fixator comparisons. We focus on a data set, based on an Ilizarov ring fixator, comprising of six variables. A modelling framework applicable to the 6D joint distribution of circular-linear data based on vine copulas is proposed. The pair-copula decomposition concept of vine copulas represents the dependence structure as a combination of circular-linear, circular-circular and linear-linear pairs modelled by their respective copulas. This framework allows us to assess the dependencies in the joint distribution as well as account for the cyclicity of the circular variables. Thus, a new approach for accurate modelling of mechanical behaviour for Ilizarov ring fixators and other data of this nature is imparted.","Fri, 15 Dec 2023 19:15:30 UTC (335 KB)"
"63","Automating reward function configuration for drug design","Marius Urbonas, Temitope Ajileye, Paul Gainer, Douglas Pires","Machine Learning (cs.LG)","Designing reward functions that guide generative molecular design (GMD) algorithms to desirable areas of chemical space is of critical importance in AI-driven drug discovery. Traditionally, this has been a manual and error-prone task; the selection of appropriate computational methods to approximate biological assays is challenging and the aggregation of computed values into a single score even more so, leading to potential reliance on trial-and-error approaches. We propose a novel approach for automated reward configuration that relies solely on experimental data, mitigating the challenges of manual reward adjustment on drug discovery projects. Our method achieves this by constructing a ranking over experimental data based on Pareto dominance over the multi-objective space, then training a neural network to approximate the reward function such that rankings determined by the predicted reward correlate with those determined by the Pareto dominance relation. We validate our method using two case studies. In the first study we simulate Design-Make-Test-Analyse (DMTA) cycles by alternating reward function updates and generative runs guided by that function. We show that the learned function adapts over time to yield compounds that score highly with respect to evaluation functions taken from the literature. In the second study we apply our algorithm to historical data from four real drug discovery projects. We show that our algorithm yields reward functions that outperform the predictive accuracy of human-defined functions, achieving an improvement of up to 0.4 in Spearman's correlation against a ground truth evaluation function that encodes the target drug profile for that project. Our method provides an efficient data-driven way to configure reward functions for GMD, and serves as a strong baseline for future research into transformative approaches for the automation of drug discovery.","Fri, 15 Dec 2023 15:09:16 UTC (38 KB)"
"64","Inferring Causality from Time Series data based on Structural Causal Model and its application to Neural Connectomics","Rahul Biswas, SuryaNarayana Sripada, Somabha Mukherjee","Methodology (stat.ME)","Inferring causation from time series data is of scientific interest in different disciplines, particularly in neural connectomics. While different approaches exist in the literature with parametric modeling assumptions, we focus on a non-parametric model for time series satisfying a Markovian structural causal model with stationary distribution and without concurrent effects. We show that the model structure can be used to its advantage to obtain an elegant algorithm for causal inference from time series based on conditional dependence tests, coined Causal Inference in Time Series (CITS) algorithm. We describe Pearson's partial correlation and Hilbert-Schmidt criterion as candidates for such conditional dependence tests that can be used in CITS for the Gaussian and non-Gaussian settings, respectively. We prove the mathematical guarantee of the CITS algorithm in recovering the true causal graph, under standard mixing conditions on the underlying time series. We also conduct a comparative evaluation of performance of CITS with other existing methodologies in simulated datasets. We then describe the utlity of the methodology in neural connectomics -- in inferring causal functional connectivity from time series of neural activity, and demonstrate its application to a real neurobiological dataset of electro-physiological recordings from the mouse visual cortex recorded by Neuropixel probes.","Fri, 15 Dec 2023 08:35:16 UTC (3,074 KB)"
"65","Bayesian Inference of Initial Conditions from Non-Linear Cosmic Structures using Field-Level Emulators","Ludvig Doeser, Drew Jamieson, Stephen Stopyra, Guilhem Lavaux, Florent Leclercq, Jens Jasche","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Analysing next-generation cosmological data requires balancing accurate modeling of non-linear gravitational structure formation and computational demands. We propose a solution by introducing a machine learning-based field-level emulator, within the Hamiltonian Monte Carlo-based Bayesian Origin Reconstruction from Galaxies (BORG) inference algorithm. Built on a V-net neural network architecture, the emulator enhances the predictions by first-order Lagrangian perturbation theory to be accurately aligned with full $N$-body simulations while significantly reducing evaluation time. We test its incorporation in BORG for sampling cosmic initial conditions using mock data based on non-linear large-scale structures from $N$-body simulations and Gaussian noise. The method efficiently and accurately explores the high-dimensional parameter space of initial conditions, fully extracting the cross-correlation information of the data field binned at a resolution of $1.95h^{-1}$ Mpc. Percent-level agreement with the ground truth in the power spectrum and bispectrum is achieved up to the Nyquist frequency $k_\mathrm{N} \approx 2.79h \; \mathrm{Mpc}^{-1}$. Posterior resimulations - using the inferred initial conditions for $N$-body simulations - show that the recovery of information in the initial conditions is sufficient to accurately reproduce halo properties. In particular, we show highly accurate $M_{200\mathrm{c}}$ halo mass function and stacked density profiles of haloes in different mass bins $[0.853,16]\times 10^{14}M_{\odot}h^{-1}$. As all available cross-correlation information is extracted, we acknowledge that limitations in recovering the initial conditions stem from the noise level and data grid resolution. This is promising as it underscores the significance of accurate non-linear modeling, indicating the potential for extracting additional information at smaller scales.","Thu, 14 Dec 2023 18:49:07 UTC (5,032 KB)"
"66","Enhancing CT Image synthesis from multi-modal MRI data based on a multi-task neural network framework","Zhuoyao Xin, Christopher Wu, Dong Liu, Chunming Gu, Jia Guo, Jun Hua","Image and Video Processing (eess.IV)","Image segmentation, real-value prediction, and cross-modal translation are critical challenges in medical imaging. In this study, we propose a versatile multi-task neural network framework, based on an enhanced Transformer U-Net architecture, capable of simultaneously, selectively, and adaptively addressing these medical image tasks. Validation is performed on a public repository of human brain MR and CT images. We decompose the traditional problem of synthesizing CT images into distinct subtasks, which include skull segmentation, Hounsfield unit (HU) value prediction, and image sequential reconstruction. To enhance the framework's versatility in handling multi-modal data, we expand the model with multiple image channels. Comparisons between synthesized CT images derived from T1-weighted and T2-Flair images were conducted, evaluating the model's capability to integrate multi-modal information from both morphological and pixel value perspectives.","Wed, 13 Dec 2023 18:22:38 UTC (960 KB)[v2] Mon, 18 Dec 2023 03:50:53 UTC (960 KB)"
"67","Topological Signal Processing on Quantum Computers for Higher-Order Network Analysis","Caesnan M. G. Leditto, Angus Southwell, Behnam Tonekaboni, Gregory A. L. White, Muhammad Usman, Kavan Modi","Quantum Physics (quant-ph)","Predicting and analyzing global behaviour of complex systems is challenging due to the intricate nature of their component interactions. Recent work has started modelling complex systems using networks endowed with multiway interactions among nodes, known as higher-order networks. In this context, simplicial complexes are a class of higher-order networks that have received significant attention due to their topological structure and connections to Hodge theory. Topological signal processing utilizes these connections to analyze and manipulate signals defined on non-Euclidean domains such as simplicial complexes. In this work, we present a general quantum algorithm for implementing filtering processes in TSP and describe its application to extracting network data based on the Hodge decomposition. We leverage pre-existing tools introduced in recent quantum algorithms for topological data analysis and combine them with spectral filtering techniques using the quantum singular value transformation framework. While this paper serves as a proof-of-concept, we obtain a super-polynomial improvement over the best known classical algorithms for TSP filtering processes, modulo some important caveats about encoding and retrieving the data from a quantum state. The proposed algorithm generalizes the applicability of tools from quantum topological data analysis to novel applications in analyzing high-dimensional complex systems.","Tue, 12 Dec 2023 19:07:32 UTC (1,849 KB)"
"68","Hybrid stars in light of the HESS J1731-347 remnant and the PREX-II experiment","P. Laskos-Patkos, P.S. Koliogiannis, Ch.C. Moustakidis","High Energy Astrophysical Phenomena (astro-ph.HE)","The recent analysis on the central compact object in the HESS J1731-347 remnant suggests interestingly small values for its mass and radius. Such an observation favors soft nuclear models that may be challenged by the observation of massive compact stars. In contrast, the recent PREX-II experiment, concerning the neutron skin thickness of $^{208}$Pb, points towards stiff equations of state that favor larger compact star radii. In the present study, we aim to explore the compatibility between stiff hadronic equations of state (favored by PREX-II) and the HESS J1731-347 remnant in the context of hybrid stars. For the construction of hybrid equations of state we use three widely employed Skyrme models combined with the well-known vector MIT bag model. Furthermore we consider two different scenarios concerning the energy density of the bag. In the first case, that of a constant bag parameter, we find that the resulting hybrid equations of state are strongly disfavored by the observation of $\sim2 M_\odot$ pulsars. However, the introduction of a Gaussian density dependence yields results that are compatible with the conservative $2 M_\odot$ constraint. The utilization of recent data based on the observation of PSR J0030+0451, PSR J0952-0607 and GW190814 allows for the imposition of additional constraints on the relevant parameters and the stiffness of the two phases. Interestingly, we find that the derived hybrid equations of state do not satisfy the PSR J0030+0451 constraints in $1\sigma$ and only marginally agree with the $2\sigma$ estimations. In addition, we estimate that the observation of massive pulsars, like PSR~J0952-0607, in combination with the existence of HESS J1731-347, may require a strong phase transition below $\sim 1.7n_0$. Finally, we show that the supermassive compact object involved in GW190814 could potentially be explained as a rapidly rotating hybrid star.","Tue, 12 Dec 2023 09:40:05 UTC (2,762 KB)"
"69","Adjustable Robust Transformer for High Myopia Screening in Optical Coherence Tomography","Xiao Ma, Zetian Zhang, Zexuan Ji, Kun Huang, Na Su, Songtao Yuan, Qiang Chen","Computer Vision and Pattern Recognition (cs.CV)","Myopia is a manifestation of visual impairment caused by an excessively elongated eyeball. Image data is critical material for studying high myopia and pathological myopia. Measurements of spherical equivalent and axial length are the gold standards for identifying high myopia, but the available image data for matching them is scarce. In addition, the criteria for defining high myopia vary from study to study, and therefore the inclusion of samples in automated screening efforts requires an appropriate assessment of interpretability. In this work, we propose a model called adjustable robust transformer (ARTran) for high myopia screening of optical coherence tomography (OCT) data. Based on vision transformer, we propose anisotropic patch embedding (APE) to capture more discriminative features of high myopia. To make the model effective under variable screening conditions, we propose an adjustable class embedding (ACE) to replace the fixed class token, which changes the output to adapt to different conditions. Considering the confusion of the data at high myopia and low myopia threshold, we introduce the label noise learning strategy and propose a shifted subspace transition matrix (SST) to enhance the robustness of the model. Besides, combining the two structures proposed above, the model can provide evidence for uncertainty evaluation. The experimental results demonstrate the effectiveness and reliability of the proposed method. Code is available at: this https URL.","Tue, 12 Dec 2023 08:08:39 UTC (6,673 KB)"
"70","Adaptive Experiments Toward Learning Treatment Effect Heterogeneity","Waverly Wei, Xinwei Ma, Jingshen Wang","Methodology (stat.ME)","Understanding treatment effect heterogeneity has become an increasingly popular task in various fields, as it helps design personalized advertisements in e-commerce or targeted treatment in biomedical studies. However, most of the existing work in this research area focused on either analyzing observational data based on strong causal assumptions or conducting post hoc analyses of randomized controlled trial data, and there has been limited effort dedicated to the design of randomized experiments specifically for uncovering treatment effect heterogeneity. In the manuscript, we develop a framework for designing and analyzing response adaptive experiments toward better learning treatment effect heterogeneity. Concretely, we provide response adaptive experimental design frameworks that sequentially revise the data collection mechanism according to the accrued evidence during the experiment. Such design strategies allow for the identification of subgroups with the largest treatment effects with enhanced statistical efficiency. The proposed frameworks not only unify adaptive enrichment designs and response-adaptive randomization designs but also complement A/B test designs in e-commerce and randomized trial designs in clinical settings. We demonstrate the merit of our design with theoretical justifications and in simulation studies with synthetic e-commerce and clinical trial data.","Mon, 11 Dec 2023 23:10:32 UTC (8,198 KB)[v2] Wed, 13 Dec 2023 17:49:51 UTC (8,198 KB)"
"71","Measuring Approximate Functional Dependencies: a Comparative Study","Marcel Parciak, Sebastiaan Weytjens, Niel Hens, Frank Neven, Liesbet M. Peeters, Stijn Vansummeren","Databases (cs.DB)","Approximate functional dependencies (AFDs) are functional dependencies (FDs) that ""almost"" hold in a relation. While various measures have been proposed to quantify the level to which an FD holds approximately, they are difficult to compare and it is unclear which measure is preferable when one needs to discover FDs in real-world data, i.e., data that only approximately satisfies the FD. In response, this paper formally and qualitatively compares AFD measures. We obtain a formal comparison through a novel presentation of measures in terms of Shannon and logical entropy. Qualitatively, we perform a sensitivity analysis w.r.t. structural properties of input relations and quantitatively study the effectiveness of AFD measures for ranking AFDs on real world data. Based on this analysis, we give clear recommendations for the AFD measures to use in practice.","Mon, 11 Dec 2023 10:57:41 UTC (393 KB)"
"72","Federated Learning Empowered by Generative Content","Rui Ye, Xinyu Zhu, Jingyi Chai, Siheng Chen, Yanfeng Wang","Machine Learning (cs.LG)","Federated learning (FL) enables leveraging distributed private data for model training in a privacy-preserving way. However, data heterogeneity significantly limits the performance of current FL methods. In this paper, we propose a novel FL framework termed FedGC, designed to mitigate data heterogeneity issues by diversifying private data with generative content. FedGC is a simple-to-implement framework as it only introduces a one-shot step of data generation. In data generation, we summarize three crucial and worth-exploring aspects (budget allocation, prompt design, and generation guidance) and propose three solution candidates for each aspect. Specifically, to achieve a better trade-off between data diversity and fidelity for generation guidance, we propose to generate data based on the guidance of prompts and real data simultaneously. The generated data is then merged with private data to facilitate local model training. Such generative data increases the diversity of private data to prevent each client from fitting the potentially biased private data, alleviating the issue of data heterogeneity. We conduct a systematic empirical study on FedGC, covering diverse baselines, datasets, scenarios, and modalities. Interesting findings include (1) FedGC consistently and significantly enhances the performance of FL methods, even when notable disparities exist between generative and private data; (2) FedGC achieves both better performance and privacy-preservation. We wish this work can inspire future works to further explore the potential of enhancing FL with generative content.","Sun, 10 Dec 2023 07:38:56 UTC (3,198 KB)"
"73","Minimum-Time Trajectory Optimization With Data-Based Models: A Linear Programming Approach","Nan Li, Ehsan Taheri, Ilya Kolmanovsky, Dimitar Filev","Systems and Control (eess.SY)","In this paper, we develop a computationally-efficient approach to minimum-time trajectory optimization using input-output data-based models, to produce an end-to-end data-to-control solution to time-optimal planning/control of dynamic systems and hence facilitate their autonomous operation. The approach integrates a non-parametric data-based model for trajectory prediction and a continuous optimization formulation based on an exponential weighting scheme for minimum-time trajectory planning. The optimization problem in its final form is a linear program and is easy to solve. We validate the approach and illustrate its application with a spacecraft relative motion planning problem.","Sun, 10 Dec 2023 01:55:21 UTC (456 KB)"
"74","Individualizing Glioma Radiotherapy Planning by Optimization of Data and Physics-Informed Discrete Loss","Michal Balcerak, Jonas Weidner, Petr Karnakov, Ivan Ezhov, Sergey Litvinov, Petros Koumoutsakos, Ray Zirui Zhang, John S. Lowengrub, Bene Wiestler, Bjoern Menze","Medical Physics (physics.med-ph)","Brain tumor growth is unique to each patient and extends beyond what is visible in imaging scans, infiltrating surrounding brain tissue. Understanding these hidden patient-specific progressions is essential for effective therapies. Current treatment plans for brain tumors, such as radiotherapy, typically involve delineating a uniform margin around the visible tumor on pre-treatment scans to target this invisible tumor growth. This ""one size fits all"" approach is derived from population studies and often fails to account for the nuances of individual patient conditions. We present the framework GliODIL which infers the full spatial distribution of tumor cell concentration from available multi-modal imaging. This is achieved through the newly introduced method of Optimizing the Discrete Loss (ODIL), where both data and physics-based constraints are softly assimilated into the solution. Our test dataset comprises 152 glioblastoma patients with pre-treatment imaging and post-treatment follow-ups for tumor recurrence monitoring. By blending data-driven techniques with physics-based constraints adapted for complex cases, GliODIL enhances recurrence prediction in radiotherapy planning, offering a superior alternative to traditional uniform margins and strict PDE adherence.","Fri, 8 Dec 2023 14:32:14 UTC (9,562 KB)[v2] Sun, 25 Feb 2024 11:33:02 UTC (13,475 KB)"
"75","Physical-Layer Semantic-Aware Network for Zero-Shot Wireless Sensing","Huixiang Zhu, Yong Xiao, Yingyu Li, Guangming Shi, Walid Saad","Networking and Internet Architecture (cs.NI)","Device-free wireless sensing has recently attracted significant interest due to its potential to support a wide range of immersive human-machine interactive applications. However, data heterogeneity in wireless signals and data privacy regulation of distributed sensing have been considered as the major challenges that hinder the wide applications of wireless sensing in large area networking systems. Motivated by the observation that signals recorded by wireless receivers are closely related to a set of physical-layer semantic features, in this paper we propose a novel zero-shot wireless sensing solution that allows models constructed in one or a limited number of locations to be directly transferred to other locations without any labeled data. We develop a novel physical-layer semantic-aware network (pSAN) framework to characterize the correlation between physical-layer semantic features and the sensing data distributions across different receivers. We then propose a pSAN-based zero-shot learning solution in which each receiver can obtain a location-specific gesture recognition model by directly aggregating the already constructed models of other receivers. We theoretically prove that models obtained by our proposed solution can approach the optimal model without requiring any local model training. Experimental results once again verify that the accuracy of models derived by our proposed solution matches that of the models trained by the real labeled data based on supervised learning approach.","Fri, 8 Dec 2023 13:50:30 UTC (194 KB)"
"76","Direct data-driven control of input saturated systems: a LMI-based approach","Federico Porcari, Valentina Breschi, Luca Zaccarian, Simone Formentin","Optimization and Control (math.OC)","In this paper, we revisit three intricate control challenges in the context of input-saturated systems, adopting a direct data-driven perspective. Diverging from the traditional two-stage process involving system identification and model-based control, our approach dispenses with the need for an explicit model description. By harnessing a combination of data-based closed-loop representation, Lyapunov theory, instrumental variables, and a generalized sector condition, we formulate data-driven linear matrix inequalities (LMIs). These LMIs are employed to maximize the basin of attraction, minimize the closed-loop reachable set with bounded disturbances, and propose a new data-driven $\ell_2$-gain minimization. Through demonstrations on benchmark examples, we shed light on the merits and limitations of transitioning from indirect to direct design strategies for input-saturated plants, emphasizing notable advantages in handling nonlinear dynamics.","Thu, 7 Dec 2023 12:52:57 UTC (1,281 KB)[v2] Sat, 9 Dec 2023 15:22:27 UTC (1,281 KB)"
"77","Reconstruction of dynamical systems from data without time labels","Zhijun Zeng, Pipi Hu, Chenglong Bao, Yi Zhu, Zuoqiang Shi","Machine Learning (cs.LG)","In this paper, we study the method to reconstruct dynamical systems from data without time labels. Data without time labels appear in many applications, such as molecular dynamics, single-cell RNA sequencing etc. Reconstruction of dynamical system from time sequence data has been studied extensively. However, these methods do not apply if time labels are unknown. Without time labels, sequence data becomes distribution data. Based on this observation, we propose to treat the data as samples from a probability distribution and try to reconstruct the underlying dynamical system by minimizing the distribution loss, sliced Wasserstein distance more specifically. Extensive experiment results demonstrate the effectiveness of the proposed method.","Thu, 7 Dec 2023 04:43:04 UTC (8,056 KB)"
"78","An efficient data-based off-policy Q-learning algorithm for optimal output feedback control of linear systems","Mohammad Alsalti, Victor G. Lopez, Matthias A. Müller","Systems and Control (eess.SY)","In this paper, we present a Q-learning algorithm to solve the optimal output regulation problem for discrete-time LTI systems. This off-policy algorithm only relies on using persistently exciting input-output data, measured offline. No model knowledge or state measurements are needed and the obtained optimal policy only uses past input-output information. Moreover, our formulation of the proposed algorithm renders it computationally efficient. We provide conditions that guarantee the convergence of the algorithm to the optimal solution. Finally, the performance of our method is compared to existing algorithms in the literature.","Wed, 6 Dec 2023 12:21:01 UTC (28 KB)"
"79","Markov Chain Monte Carlo Data Association for Sets of Trajectories","Yuxuan Xia, Ángel F. García-Fernández, Lennart Svensson","Signal Processing (eess.SP)","This paper considers a batch solution to the multi-object tracking problem based on sets of trajectories. Specifically, we present two offline implementations of the trajectory Poisson multi-Bernoulli mixture (TPMBM) filter for batch data based on Markov chain Monte Carlo (MCMC) sampling of the data association hypotheses. In contrast to online TPMBM implementations, the proposed offline implementations solve a large-scale, multi-scan data association problem across the entire time interval of interest, and therefore they can fully exploit all the measurement information available. Furthermore, by leveraging the efficient hypothesis structure of TPMBM filters, the proposed implementations compare favorably with other MCMC-based multi-object tracking algorithms. Simulation results show that the TPMBM implementation using the Metropolis-Hastings algorithm presents state-of-the-art multiple trajectory estimation performance.","Wed, 6 Dec 2023 11:12:43 UTC (1,248 KB)"
"80","Projection Regret: Reducing Background Bias for Novelty Detection via Diffusion Models","Sungik Choi, Hankook Lee, Honglak Lee, Moontae Lee","Machine Learning (cs.LG)","Novelty detection is a fundamental task of machine learning which aims to detect abnormal ($\textit{i.e.}$ out-of-distribution (OOD)) samples. Since diffusion models have recently emerged as the de facto standard generative framework with surprising generation results, novelty detection via diffusion models has also gained much attention. Recent methods have mainly utilized the reconstruction property of in-distribution samples. However, they often suffer from detecting OOD samples that share similar background information to the in-distribution data. Based on our observation that diffusion models can \emph{project} any sample to an in-distribution sample with similar background information, we propose \emph{Projection Regret (PR)}, an efficient novelty detection method that mitigates the bias of non-semantic information. To be specific, PR computes the perceptual distance between the test image and its diffusion-based projection to detect abnormality. Since the perceptual distance often fails to capture semantic changes when the background information is dominant, we cancel out the background bias by comparing it against recursive projections. Extensive experiments demonstrate that PR outperforms the prior art of generative-model-based novelty detection methods by a significant margin.","Tue, 5 Dec 2023 09:44:47 UTC (4,537 KB)"
"81","Prompt Optimization via Adversarial In-Context Learning","Xuan Long Do, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Qizhe Xie, Junxian He","Machine Learning (cs.LG)","We propose a new method, Adversarial In-Context Learning (adv-ICL), to optimize prompt for in-context learning (ICL) by employing one LLM as a generator, another as a discriminator, and a third as a prompt modifier. As in traditional adversarial learning, adv-ICL is implemented as a two-player game between the generator and discriminator, where the generator tries to generate realistic enough output to fool the discriminator. In each round, given an input prefixed by task instructions and several exemplars, the generator produces an output. The discriminator is then tasked with classifying the generator input-output pair as model-generated or real data. Based on the discriminator loss, the prompt modifier proposes possible edits to the generator and discriminator prompts, and the edits that most improve the adversarial loss are selected. We show that adv-ICL results in significant improvements over state-of-the-art prompt optimization techniques for both open and closed-source models on 11 generation and classification tasks including summarization, arithmetic reasoning, machine translation, data-to-text generation, and the MMLU and big-bench hard benchmarks. In addition, because our method uses pre-trained models and updates only prompts rather than model parameters, it is computationally efficient, easy to extend to any LLM and task, and effective in low-resource settings.","Tue, 5 Dec 2023 09:44:45 UTC (1,923 KB)"
"82","An AI-based solution for the cold start and data sparsity problems in the recommendation systems","Shahriar Shakir Sumit","Information Retrieval (cs.IR)","In recent years, the amount of data available on the internet and the number of users who utilize the Internet have increased at an unparalleled pace. The exponential development in the quantity of digital information accessible and the number of Internet users has created the possibility for information overload, impeding fast access to items of interest on the Internet. Information retrieval systems like as Google, DevilFinder, and Altavista have partly overcome this challenge, but prioritizing and customization of information (where a system maps accessible material to a user's interests and preferences) were lacking. This has resulted in a higher-than-ever need for recommender systems. Recommender systems are information filtering systems that address the issue of information overload by filtering important information fragments from a huge volume of dynamically produced data based on the user's interests, favorite things, preferences and ratings on the desired item. Recommender systems can figure out if a person would like an item or not based on their profile.","Mon, 4 Dec 2023 12:25:05 UTC (186 KB)[v2] Tue, 9 Jan 2024 10:56:43 UTC (1 KB) (withdrawn)"
"83","Large Language Models for Travel Behavior Prediction","Baichuan Mo, Hanyong Xu, Dingyi Zhuang, Ruoyun Ma, Xiaotong Guo, Jinhua Zhao","Machine Learning (cs.LG)","Travel behavior prediction is a fundamental task in transportation demand management. The conventional methods for travel behavior prediction rely on numerical data to construct mathematical models and calibrate model parameters to represent human preferences. Recent advancement in large language models (LLMs) has shown great reasoning abilities to solve complex problems. In this study, we propose to use LLMs to predict travel behavior with prompt engineering without data-based parameter learning. Specifically, we carefully design our prompts that include 1) task description, 2) travel characteristics, 3) individual attributes, and 4) guides of thinking with domain knowledge, and ask the LLMs to predict an individual's travel behavior and explain the results. We select the travel mode choice task as a case study. Results show that, though no training samples are provided, LLM-based predictions have competitive accuracy and F1-score as canonical supervised learning methods such as multinomial logit, random forest, and neural networks. LLMs can also output reasons that support their prediction. However, though in most of the cases, the output explanations are reasonable, we still observe cases that violate logic or with hallucinations.","Thu, 30 Nov 2023 04:35:55 UTC (1,901 KB)"
"84","A Compact Implicit Neural Representation for Efficient Storage of Massive 4D Functional Magnetic Resonance Imaging","Ruoran Li, Runzhao Yang, Wenxin Xiang, Yuxiao Cheng, Tingxiong Xiao, Jinli Suo","Image and Video Processing (eess.IV)","Functional Magnetic Resonance Imaging (fMRI) data is a kind of widely used four-dimensional biomedical data, demanding effective compression but presenting unique challenges for compression due to its intricate temporal dynamics, low signal-to-noise ratio, and complicated underlying redundancies. This paper reports a novel compression paradigm specifically tailored for fMRI data based on Implicit Neural Representation (INR). The proposed approach focuses on removing the various redundancies among the time series, including (i) conducting spatial correlation modeling for intra-region dynamics, (ii) decomposing reusable neuronal activation patterns, and using proper initialization together with nonlinear fusion to describe the inter-region similarity. The above scheme properly incorporates the unique features of fMRI data, and experimental results on publicly available datasets demonstrate the effectiveness of the proposed method, surpassing state-of-the-art algorithms in both conventional image quality evaluation metrics and fMRI downstream tasks. This work in this paper paves the way for sharing massive fMRI data at low bandwidth and high fidelity.","Thu, 30 Nov 2023 05:54:37 UTC (6,246 KB)"
"85","MoDS: Model-oriented Data Selection for Instruction Tuning","Qianlong Du, Chengqing Zong, Jiajun Zhang","Computation and Language (cs.CL)","Instruction tuning has become the de facto method to equip large language models (LLMs) with the ability of following user instructions. Usually, hundreds of thousands or millions of instruction-following pairs are employed to fine-tune the foundation LLMs. Recently, some studies show that a small number of high-quality instruction data is enough. However, how to select appropriate instruction data for a given LLM is still an open problem. To address this problem, in this paper we present a model-oriented data selection (MoDS) approach, which selects instruction data based on a new criteria considering three aspects: quality, coverage and necessity. First, our approach utilizes a quality evaluation model to filter out the high-quality subset from the original instruction dataset, and then designs an algorithm to further select from the high-quality subset a seed instruction dataset with good coverage. The seed dataset is applied to fine-tune the foundation LLM to obtain an initial instruction-following LLM. Finally, we develop a necessity evaluation model to find out the instruction data which are performed badly in the initial instruction-following LLM and consider them necessary instructions to further improve the LLMs. In this way, we can get a small high-quality, broad-coverage and high-necessity subset from the original instruction datasets. Experimental results show that, the model fine-tuned with 4,000 instruction pairs selected by our approach could perform better than the model fine-tuned with the full original dataset which includes 214k instruction data.","Mon, 27 Nov 2023 09:33:13 UTC (641 KB)"
"86","Optimizing and Fine-tuning Large Language Model for Urban Renewal","Xi Wang, Xianyao Ling, Tom Zhang, Xuecao Li, Shaolan Wang, Zhixing Li, Liang Zhang, Peng Gong","Computation and Language (cs.CL)","This study aims to innovatively explore adaptive applications of large language models (LLM) in urban renewal. It also aims to improve its performance and text generation quality for knowledge question-answering (QA) tasks. Based on the ChatGLM, we automatically generate QA datasets using urban renewal scientific literature corpora in a self-instruct manner and then conduct joint fine-tuning training on the model using the Prefix and LoRA fine-tuning methods to create an LLM for urban renewal. By guiding the LLM to automatically generate QA data based on prompt words and given text, it is possible to quickly obtain datasets in the urban renewal field and provide data support for the fine-tuning training of LLMs. The experimental results show that the joint fine-tuning training method proposed in this study can significantly improve the performance of LLM on the QA tasks. Compared with LoRA fine-tuning, the method improves the Bleu and Rouge metrics on the test by about 5%; compared with the model before fine-tuning, the method improves the Bleu and Rouge metrics by about 15%-20%. This study demonstrates the effectiveness and superiority of the joint fine-tuning method using Prefix and LoRA for ChatGLM in the urban renewal knowledge QA tasks. It provides a new approach for fine-tuning LLMs on urban renewal-related tasks.","Mon, 27 Nov 2023 02:17:11 UTC (631 KB)"
"87","Privacy-Preserving Data Sharing in Agriculture: Enforcing Policy Rules for Secure and Confidential Data Synthesis","Anantaa Kotal, Lavanya Elluri, Deepti Gupta, Varun Mandalapu, Anupam Joshi","Cryptography and Security (cs.CR)","Big Data empowers the farming community with the information needed to optimize resource usage, increase productivity, and enhance the sustainability of agricultural practices. The use of Big Data in farming requires the collection and analysis of data from various sources such as sensors, satellites, and farmer surveys. While Big Data can provide the farming community with valuable insights and improve efficiency, there is significant concern regarding the security of this data as well as the privacy of the participants. Privacy regulations, such as the EU GDPR, the EU Code of Conduct on agricultural data sharing by contractual agreement, and the proposed EU AI law, have been created to address the issue of data privacy and provide specific guidelines on when and how data can be shared between organizations. To make confidential agricultural data widely available for Big Data analysis without violating the privacy of the data subjects, we consider privacy-preserving methods of data sharing in agriculture. Deep learning-based synthetic data generation has been proposed for privacy-preserving data sharing. However, there is a lack of compliance with documented data privacy policies in such privacy-preserving efforts. In this study, we propose a novel framework for enforcing privacy policy rules in privacy-preserving data generation algorithms. We explore several available agricultural codes of conduct, extract knowledge related to the privacy constraints in data, and use the extracted knowledge to define privacy bounds in a privacy-preserving generative model. We use our framework to generate synthetic agricultural data and present experimental results that demonstrate the utility of the synthetic dataset in downstream tasks. We also show that our framework can evade potential threats and secure data based on applicable regulatory policy rules.","Mon, 27 Nov 2023 00:12:47 UTC (830 KB)"
"88","GAN-Based LiDAR Intensity Simulation","Richard Marcus, Felix Gabel, Niklas Knoop, Marc Stamminger","Computer Vision and Pattern Recognition (cs.CV)","Realistic vehicle sensor simulation is an important element in developing autonomous driving. As physics-based implementations of visual sensors like LiDAR are complex in practice, data-based approaches promise solutions. Using pairs of camera images and LiDAR scans from real test drives, GANs can be trained to translate between them. For this process, we contribute two additions. First, we exploit the camera images, acquiring segmentation data and dense depth maps as additional input for training. Second, we test the performance of the LiDAR simulation by testing how well an object detection network generalizes between real and synthetic point clouds to enable evaluation without ground truth point clouds. Combining both, we simulate LiDAR point clouds and demonstrate their realism.","Sun, 26 Nov 2023 20:44:09 UTC (5,874 KB)"
"89","Real-time Digital Twins","Dirk Hartmann","Computers and Society (cs.CY)","We live in a world of exploding complexity driven by technical evolution as well as highly volatile socio-economic environments. Managing complexity is a key issue in everyday decision making such as providing safe, sustainable, and efficient industrial control solutions as well as solving today's global grand challenges such as the climate change. However, the level of complexity has well reached our cognitive capability to take informed decisions. Digital Twins, tightly integrating the real and the digital world, are a key enabler to support decision making for complex systems. They allow informing operational as well as strategic decisions upfront through accepted virtual predictions and optimizations of their real-world counter parts. Here we focus on real-time Digital Twins for online prediction and optimization of highly dynamic industrial assets and processes. They offer significant opportunities in the context of the industrial Internet of Things for novel and more effective control and optimization concepts. Thereby, they meet the Internet of Things needs for novel technologies to overcome today's limitations in terms of data availability in industrial contexts. Integrating today's seemingly complementary technologies of model-based and data-based, as well as edge-based and cloud-based approaches has the potential to re-imagine industrial process performance optimization solutions.","Mon, 6 Nov 2023 08:46:48 UTC (862 KB)"
"90","Coevolution of Neural Architectures and Features for Stock Market Forecasting: A Multi-objective Decision Perspective","Faizal Hafiz, Jan Broekaert, Davide La Torre, Akshya Swain","Computational Engineering, Finance, and Science (cs.CE)","In a multi objective setting, a portfolio manager's highly consequential decisions can benefit from assessing alternative forecasting models of stock index movement. The present investigation proposes a new approach to identify a set of nondominated neural network models for further selection by the decision maker. A new coevolution approach is proposed to simultaneously select the features and topology of neural networks (collectively referred to as neural architecture), where the features are viewed from a topological perspective as input neurons. Further, the coevolution is posed as a multicriteria problem to evolve sparse and efficacious neural architectures. The well known dominance and decomposition based multiobjective evolutionary algorithms are augmented with a nongeometric crossover operator to diversify and balance the search for neural architectures across conflicting criteria. Moreover, the coevolution is augmented to accommodate the data based implications of distinct market behaviors prior to and during the ongoing COVID 19 pandemic. A detailed comparative evaluation is carried out with the conventional sequential approach of feature selection followed by neural topology design, as well as a scalarized coevolution approach. The results on the NASDAQ index in pre and peri COVID time windows convincingly demonstrate that the proposed coevolution approach can evolve a set of nondominated neural forecasting models with better generalization capabilities.","Thu, 23 Nov 2023 15:12:30 UTC (1,911 KB)"
"91","Robust Multi-Model Subset Selection","Anthony-Alexander Christidis, Gabriela Cohen-Freue","Methodology (stat.ME)","Modern datasets in biology and chemistry are often characterized by the presence of a large number of variables and outlying samples due to measurement errors or rare biological and chemical profiles. To handle the characteristics of such datasets we introduce a method to learn a robust ensemble comprised of a small number of sparse, diverse and robust models, the first of its kind in the literature. The degree to which the models are sparse, diverse and resistant to data contamination is driven directly by the data based on a cross-validation criterion. We establish the finite-sample breakdown of the ensembles and the models that comprise them, and we develop a tailored computing algorithm to learn the ensembles by leveraging recent developments in l0 optimization. Our extensive numerical experiments on synthetic and artificially contaminated real datasets from bioinformatics and cheminformatics demonstrate the competitive advantage of our method over state-of-the-art sparse and robust methods. We also demonstrate the applicability of our proposal on a cardiac allograft vasculopathy dataset.","Wed, 22 Nov 2023 07:11:17 UTC (24 KB)[v2] Thu, 14 Dec 2023 06:24:22 UTC (354 KB)"
"92","Identification of Ammonium Salts on Comet 67P/C-G Surface from Infrared VIRTIS/Rosetta Data Based on Laboratory Experiments. Implications and Perspectives","Olivier Poch (IPAG), Istiqomah Istiqomah (IPAG), Eric Quirico (IPAG), Pierre Beck (IPAG), Bernard Schmitt (IPAG), Patrice Theulé, Alexandre Faure (IPAG), Pierre Hily-Blant (IPAG), Lydie Bonal (IPAG), Andrea Raponi, Mauro Ciarniello, Batiste Rousseau (IPAG), Sandra Potin (IPAG), Olivier Brissaud (IPAG), Laurène Flandinet (IPAG), Gianrico Filacchione, Antoine Pommerol, Nicolas Thomas, David Kappel, Vito Mennella, Lyuba Moroz, Vassilissa Vinogradoff, Gabriele Arnold, Stéphane Erard, Dominique Bockelée-Morvan, Cédric Leyrat, Fabrizio Capaccioni, Maria Cristina de Sanctis, Andrea Longobardo, Francesca Mancarella, Ernesto Palomba, Federico Tosi","Earth and Planetary Astrophysics (astro-ph.EP)","The nucleus of comet 67P/Churyumov-Gerasimenko exhibits a broad spectral reflectance feature around 3.2 $\mu$m, which is omnipresent in all spectra of the surface, and whose attribution has remained elusive since its discovery. Based on laboratory experiments, we have shown that most of this absorption feature is due to ammonium (NH4+) salts mixed with the dark surface material. The depth of the band is compatible with semi-volatile ammonium salts being a major reservoir of nitrogen in the comet, which could dominate over refractory organic matter and volatile species. These salts may thus represent the long-sought reservoir of nitrogen in comets, possibly bringing their nitrogen-to-carbon ratio in agreement with the solar value. Moreover, the reflectance spectra of several asteroids are compatible with the presence of NH4+ salts at their surfaces. The presence of such salts, and other NH4+-bearing compounds on asteroids, comets, and possibly in proto-stellar environments, suggests that NH4+ may be a tracer of the incorporation and transformation of nitrogen in ices, minerals and organics, at different phases of the formation of the Solar System.","Mon, 20 Nov 2023 12:29:05 UTC (215 KB)"
"93","RflyMAD: A Dataset for Multicopter Fault Detection and Health Assessment","Xiangli Le, Bo Jin, Gen Cui, Xunhua Dai, Quan Quan","Robotics (cs.RO)","This paper presents an open-source dataset RflyMAD, a Multicopter Abnomal Dataset developed by Reliable Flight Control (Rfly) Group aiming to promote the development of research fields like fault detection and isolation (FDI) or health assessment (HA). The entire 114 GB dataset includes 11 types of faults under 6 flight statuses which are adapted from ADS-33 file to cover more occasions in which the multicopters have different mobility levels when faults occur. In the total 5629 flight cases, the fault time is up to 3283 minutes, and there are 2566 cases for software-in-the-loop (SIL) simulation, 2566 cases for hardware-in-the-loop (HIL) simulation and 497 cases for real flight. As it contains simulation data based on RflySim and real flight data, it is possible to improve the quantity while increasing the data quality. In each case, there are ULog, Telemetry log, Flight information and processed files for researchers to use and check. The RflyMAD dataset could be used as a benchmark for fault diagnosis methods and the support relationship between simulation data and real flight is verified through transfer learning methods. More methods as a baseline will be presented in the future, and RflyMAD will be updated with more data and types. In addition, the dataset and related toolkit can be accessed through this https URL.","Sun, 19 Nov 2023 14:52:45 UTC (598 KB)[v2] Thu, 11 Jan 2024 07:34:38 UTC (598 KB)"
"94","Robust Control of Unknown Switched Linear Systems from Noisy Data","Wenjie Liu, Yifei Li, Jian Sun, Gang Wang, Jie Chen","Systems and Control (eess.SY)","This paper investigates the problem of data-driven stabilization for linear discrete-time switched systems with unknown switching dynamics. In the absence of noise, a data-based state feedback stabilizing controller can be obtained by solving a semi-definite program (SDP) on-the-fly, which automatically adapts to the changes of switching dynamics. However, when noise is present, the persistency of excitation condition based on the closed-loop data may be undermined, rendering the SDP infeasible. To address this issue, an auxiliary function-based switching control law is proposed, which only requires intermittent SDP solutions when its feasibility is guaranteed. By analyzing the relationship between the controller and the system switching times, it is shown that the proposed controller guarantees input-to-state practical stability (ISpS) of the closed-loop switched linear system, provided that the noise is bounded and the dynamics switches slowly enough. Two numerical examples are presented to verify the effectiveness of the proposed controller.","Sun, 19 Nov 2023 11:19:36 UTC (471 KB)"
"95","Challenges in data-based geospatial modeling for environmental research and practice","Diana Koldasbayeva, Polina Tregubova, Mikhail Gasanov, Alexey Zaytsev, Anna Petrovskaia, Evgeny Burnaev","Machine Learning (cs.LG)","With the rise of electronic data, particularly Earth observation data, data-based geospatial modelling using machine learning (ML) has gained popularity in environmental research. Accurate geospatial predictions are vital for domain research based on ecosystem monitoring and quality assessment and for policy-making and action planning, considering effective management of natural resources. The accuracy and computation speed of ML has generally proved efficient. However, many questions have yet to be addressed to obtain precise and reproducible results suitable for further use in both research and practice. A better understanding of the ML concepts applicable to geospatial problems enhances the development of data science tools providing transparent information crucial for making decisions on global challenges such as biosphere degradation and climate change. This survey reviews common nuances in geospatial modelling, such as imbalanced data, spatial autocorrelation, prediction errors, model generalisation, domain specificity, and uncertainty estimation. We provide an overview of techniques and popular programming tools to overcome or account for the challenges. We also discuss prospects for geospatial Artificial Intelligence in environmental applications.","Sat, 18 Nov 2023 12:30:49 UTC (22,317 KB)"
"96","Multi-delay arterial spin-labeled perfusion estimation with biophysics simulation and deep learning","Renjiu Hu, Qihao Zhang, Pascal Spincemaille, Thanh D. Nguyen, Yi Wang","Quantitative Methods (q-bio.QM)","Purpose: To develop biophysics-based method for estimating perfusion Q from arterial spin labeling (ASL) images using deep learning. Methods: A 3D U-Net (QTMnet) was trained to estimate perfusion from 4D tracer propagation images. The network was trained and tested on simulated 4D tracer concentration data based on artificial vasculature structure generated by constrained constructive optimization (CCO) method. The trained network was further tested in a synthetic brain ASL image based on vasculature network extracted from magnetic resonance (MR) angiography. The estimations from both trained network and a conventional kinetic model were compared in ASL images acquired from eight healthy volunteers. Results: QTMnet accurately reconstructed perfusion Q from concentration data. Relative error of the synthetic brain ASL image was 7.04% for perfusion Q, lower than the error using single-delay ASL model: 25.15% for Q, and multi-delay ASL model: 12.62% for perfusion Q. Conclusion: QTMnet provides accurate estimation on perfusion parameters and is a promising approach as a clinical ASL MRI image processing pipeline.","Fri, 17 Nov 2023 16:55:14 UTC (1,316 KB)"
"97","Concept-free Causal Disentanglement with Variational Graph Auto-Encoder","Jingyun Feng, Lin Zhang, Lili Yang","Machine Learning (cs.LG)","In disentangled representation learning, the goal is to achieve a compact representation that consists of all interpretable generative factors in the observational data. Learning disentangled representations for graphs becomes increasingly important as graph data rapidly grows. Existing approaches often rely on Variational Auto-Encoder (VAE) or its causal structure learning-based refinement, which suffer from sub-optimality in VAEs due to the independence factor assumption and unavailability of concept labels, respectively. In this paper, we propose an unsupervised solution, dubbed concept-free causal disentanglement, built on a theoretically provable tight upper bound approximating the optimal factor. This results in an SCM-like causal structure modeling that directly learns concept structures from data. Based on this idea, we propose Concept-free Causal VGAE (CCVGAE) by incorporating a novel causal disentanglement layer into Variational Graph Auto-Encoder. Furthermore, we prove concept consistency under our concept-free causal disentanglement framework, hence employing it to enhance the meta-learning framework, called concept-free causal Meta-Graph (CC-Meta-Graph). We conduct extensive experiments to demonstrate the superiority of the proposed models: CCVGAE and CC-Meta-Graph, reaching up to $29\%$ and $11\%$ absolute improvements over baselines in terms of AUC, respectively.","Fri, 17 Nov 2023 16:50:00 UTC (2,400 KB)"
"98","Tensor-SqRA: Modeling the Transition Rates of Interacting Molecular Systems in terms of Potential Energies","Alexander Sikorski, Amir Niknejad, Marcus Weber, Luca Donati","Chemical Physics (physics.chem-ph)","Estimating the rate of rare conformational changes in molecular systems is one of the goals of Molecular Dynamics simulations. In the past decades, a lot of progress has been done in data-based approaches towards this problem. In contrast, model-based methods such as the Square Root Approximation (SqRA), directly derive these quantities from the potential energy functions. In this article we demonstrate how the SqRA formalism naturally blends with the tensor structure obtained by coupling multiple systems, resulting in the tensor-based Square Root Approximation (tSqRA). It enables efficient treatment of high-dimensional systems using the SqRA and provides an algebraic expression of the impact of coupling energies between molecular subsystems. Based on the tSqRA, we also develop the Projected Rate Estimation (PRE), a hybrid data-model-based algorithm that efficiently estimates the slowest rates for coupled systems. In addition, we investigate the possibility of integrating low-rank approximations within this framework to maximize the potential of the tSqRA.","Thu, 16 Nov 2023 11:02:21 UTC (4,049 KB)"
"99","R-Tuning: Teaching Large Language Models to Refuse Unknown Questions","Hanning Zhang, Shizhe Diao, Yong Lin, Yi R. Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, Tong Zhang","Computation and Language (cs.CL)","Large language models (LLMs) have revolutionized numerous domains with their impressive performance but still face their challenges. A predominant issue is the propensity for these models to generate non-existent facts, a concern termed hallucination. Our research is motivated by the observation that previous instruction tuning methods force the model to complete a sentence no matter whether the model knows the knowledge or not. When the question is out of the parametric knowledge, it will try to make up something and fail to indicate when it lacks knowledge. In this paper, we present a new approach called Refusal-Aware Instruction Tuning (R-Tuning). This approach is formalized by first identifying the knowledge gap between parametric knowledge and the instruction tuning data. Then, we construct the refusal-aware data based on the knowledge intersection, to tune LLMs to refrain from responding to questions beyond its parametric knowledge. Experimental results demonstrate this new instruction tuning approach effectively improves a model's ability to answer known questions and refrain from answering unknown questions. Furthermore, when tested on out-of-domain datasets, the refusal ability was found to be a meta-skill that could be generalized to other tasks. Further analysis surprisingly finds that learning the uncertainty during training displays a better ability to estimate uncertainty than uncertainty-based testing. Our code will be released at this https URL.","Thu, 16 Nov 2023 08:45:44 UTC (25,842 KB)"
"100","Disentangling the Potential Impacts of Papers into Diffusion, Conformity, and Contribution Values","Zhikai Xue, Guoxiu He, Zhuoren Jiang, Sichen Gu, Yangyang Kang, Star Zhao, Wei Lu","Social and Information Networks (cs.SI)","The potential impact of an academic paper is determined by various factors, including its popularity and contribution. Existing models usually estimate original citation counts based on static graphs and fail to differentiate values from nuanced perspectives. In this study, we propose a novel graph neural network to Disentangle the Potential impacts of Papers into Diffusion, Conformity, and Contribution values (called DPPDCC). Given a target paper, DPPDCC encodes temporal and structural features within the constructed dynamic heterogeneous graph. Particularly, to capture the knowledge flow, we emphasize the importance of comparative and co-cited/citing information between papers and aggregate snapshots evolutionarily. To unravel popularity, we contrast augmented graphs to extract the essence of diffusion and predict the accumulated citation binning to model conformity. We further apply orthogonal constraints to encourage distinct modeling of each perspective and preserve the inherent value of contribution. To evaluate models' generalization for papers published at various times, we reformulate the problem by partitioning data based on specific time points to mirror real-world conditions. Extensive experimental results on three datasets demonstrate that DPPDCC significantly outperforms baselines for previously, freshly, and immediately published papers. Further analyses confirm its robust capabilities. We will make our datasets and codes publicly available.","Wed, 15 Nov 2023 07:21:11 UTC (285 KB)[v2] Thu, 18 Jan 2024 17:38:59 UTC (3,978 KB)"
"101","SDSS-IV from 2014 to 2016: A Detailed Demographic Comparison over Three Years","Amy M. Jones, Rachael L. Beaton, Brian A. Cherinka, Karen L. Masters, Sara Lucatello, Aleksandar M. Diamond-Stanic, Sarah A. Bird, Michael R. Blanton, Katia Cunha, Emily E. Farr, Diane Feuillet, Peter M. Frinchaboy, Alex Hagen, Karen Kinemuchi, Britt Lundgren, Mariarosa L. Marinelli, Adam D. Myers, Alexandre Roman-Lopes, Ashley J. Ross, Jose R. Sanchez-Gallego, Sarah J. Schmidt, Jennifer Sobeck, Keivan G. Stassun, Jamie Tayar, Mariana Vargas-Magana, J. C. Wilson, Gail Zasowski","Instrumentation and Methods for Astrophysics (astro-ph.IM)","The Sloan Digital Sky Survey (SDSS) is one of the largest international astronomy organizations. We present demographic data based on surveys of its members from 2014, 2015 and 2016, during the fourth phase of SDSS (SDSS-IV). We find about half of SDSS-IV collaboration members were based in North America, a quarter in Europe, and the remainder in Asia and Central and South America. Overall, 26-36% are women (from 2014 to 2016), up to 2% report non-binary genders. 11-14% report that they are racial or ethnic minorities where they live. The fraction of women drops with seniority, and is also lower among collaboration leadership. Men in SDSS-IV were more likely to report being in a leadership role, and for the role to be funded and formally recognized. SDSS-IV collaboration members are twice as likely to have a parent with a college degree, than the general population, and are ten times more likely to have a parent with a PhD. This trend is slightly enhanced for female collaboration members. Despite this, the fraction of first generation college students (FGCS) is significant (31%). This fraction increased among collaboration members who are racial or ethnic minorities (40-50%), and decreased among women (15-25%). SDSS-IV implemented many inclusive policies and established a dedicated committee, the Committee on INclusiveness in SDSS (COINS). More than 60% of the collaboration agree that the collaboration is inclusive; however, collaboration leadership more strongly agree with this than the general membership. In this paper, we explain these results in full, including the history of inclusive efforts in SDSS-IV. We conclude with a list of suggested recommendations based on our findings, which can be used to improve equity and inclusion in large astronomical collaborations, which we argue is not only moral, but will also optimize their scientific output.","Wed, 15 Nov 2023 14:03:24 UTC (4,495 KB)"
"102","Taxonomy, Semantic Data Schema, and Schema Alignment for Open Data in Urban Building Energy Modeling","Liang Zhang, Jianli Chen, Jia Zou","Databases (cs.DB)","Urban Building Energy Modeling (UBEM) is a critical tool to provide quantitative analysis on building decarbonization, sustainability, building-to-grid integration, and renewable energy applications on city, regional, and national scales. Researchers usually use open data as inputs to build and calibrate UBEM. However, open data are from thousands of sources covering various perspectives of weather, building characteristics, etc. Besides, a lack of semantic features of open data further increases the engineering effort to process information to be directly used for UBEM as inputs. In this paper, we first reviewed open data types used for UBEM and developed a taxonomy to categorize open data. Based on that, we further developed a semantic data schema for each open data category to maintain data consistency and improve model automation for UBEM. In a case study, we use three popular open data to show how they can be automatically processed based on the proposed schematic data structure using large language models. The accurate results generated by large language models indicate the machine-readability and human-interpretability of the developed semantic data schema.","Tue, 14 Nov 2023 21:00:26 UTC (714 KB)"
"103","Total Empiricism: Learning from Data","Orestis Loukas, Ho Ryun Chung","Statistics Theory (math.ST)","Statistical analysis is an important tool to distinguish systematic from chance findings. Current statistical analyses rely on distributional assumptions reflecting the structure of some underlying model, which if not met lead to problems in the analysis and interpretation of the results. Instead of trying to fix the model or ""correct"" the data, we here describe a totally empirical statistical approach that does not rely on ad hoc distributional assumptions in order to overcome many problems in contemporary statistics. Starting from elementary combinatorics, we motivate an information-guided formalism to quantify knowledge extracted from the given data. Subsequently, we derive model-agnostic methods to identify patterns that are solely evidenced by the data based on our prior knowledge. The data-centric character of empiricism allows for its universal applicability, particularly as sample size grows larger. In this comprehensive framework, we re-interpret and extend model distributions, scores and statistical tests used in different schools of statistics.","Tue, 14 Nov 2023 16:59:37 UTC (73 KB)"
"104","Online Data-driven Control Against False Data Injection Attacks","Wenjie Liu, Lidong Li, Jian Sun, Fang Deng, Gang Wang, Jie Chen","Systems and Control (eess.SY)","The rise of cyber-security concerns has brought significant attention to the analysis and design of cyber-physical systems (CPSs). Among the various types of cyberattacks, denial-of-service (DoS) attacks and false data injection (FDI) attacks can be easily launched and have become prominent threats. While resilient control against DoS attacks has received substantial research efforts, countermeasures developed against FDI attacks have been relatively limited, particularly when explicit system models are not available. To address this gap, the present paper focuses on the design of data-driven controllers for unknown linear systems subject to FDI attacks on the actuators, utilizing input-state data. To this end, a general FDI attack model is presented, which imposes minimally constraints on the switching frequency of attack channels and the magnitude of attack matrices. A dynamic state feedback control law is designed based on offline and online input-state data, which adapts to the channel switching of FDI attacks. This is achieved by solving two data-based semi-definite programs (SDPs) on-the-fly to yield a tight approximation of the set of subsystems consistent with both offline clean data and online attack-corrupted data. It is shown that under mild conditions on the attack, the proposed SDPs are recursively feasible and controller achieves exponential stability. Numerical examples showcase its effectiveness in mitigating the impact of FDI attacks.","Tue, 14 Nov 2023 14:44:16 UTC (3,661 KB)"
"105","Understanding learning from EEG data: Combining machine learning and feature engineering based on hidden Markov models and mixed models","Gabriel Rodrigues Palma, Conor Thornberry, Seán Commins, Rafael de Andrade Moral","Quantitative Methods (q-bio.QM)","Theta oscillations, ranging from 4-8 Hz, play a significant role in spatial learning and memory functions during navigation tasks. Frontal theta oscillations are thought to play an important role in spatial navigation and memory. Electroencephalography (EEG) datasets are very complex, making any changes in the neural signal related to behaviour difficult to interpret. However, multiple analytical methods are available to examine complex data structure, especially machine learning based techniques. These methods have shown high classification performance and the combination with feature engineering enhances the capability of these methods. This paper proposes using hidden Markov and linear mixed effects models to extract features from EEG data. Based on the engineered features obtained from frontal theta EEG data during a spatial navigation task in two key trials (first, last) and between two conditions (learner and non-learner), we analysed the performance of six machine learning methods (Polynomial Support Vector Machines, Non-linear Support Vector Machines, Random Forests, K-Nearest Neighbours, Ridge, and Deep Neural Networks) on classifying learner and non-learner participants. We also analysed how different standardisation methods used to pre-process the EEG data contribute to classification performance. We compared the classification performance of each trial with data gathered from the same subjects, including solely coordinate-based features, such as idle time and average speed. We found that more machine learning methods perform better classification using coordinate-based data. However, only deep neural networks achieved an area under the ROC curve higher than 80% using the theta EEG data alone. Our findings suggest that standardising the theta EEG data and using deep neural networks enhances the classification of learner and non-learner subjects in a spatial learning task.","Tue, 14 Nov 2023 12:24:12 UTC (1,761 KB)"
"106","Interpretable Fine-Tuning for Graph Neural Network Surrogate Models","Shivam Barwey, Romit Maulik","Machine Learning (cs.LG)","Data-based surrogate modeling has surged in capability in recent years with the emergence of graph neural networks (GNNs), which can operate directly on mesh-based representations of data. The goal of this work is to introduce an interpretable fine-tuning strategy for GNNs, with application to unstructured mesh-based fluid dynamics modeling. The end result is a fine-tuned GNN that adds interpretability to a pre-trained baseline GNN through an adaptive sub-graph sampling strategy that isolates regions in physical space intrinsically linked to the forecasting task, while retaining the predictive capability of the baseline. The structures identified by the fine-tuned GNNs, which are adaptively produced in the forward pass as explicit functions of the input, serve as an accessible link between the baseline model architecture, the optimization goal, and known problem-specific physics. Additionally, through a regularization procedure, the fine-tuned GNNs can also be used to identify, during inference, graph nodes that correspond to a majority of the anticipated forecasting error, adding a novel interpretable error-tagging capability to baseline models. Demonstrations are performed using unstructured flow data sourced from flow over a backward-facing step at high Reynolds numbers.","Mon, 13 Nov 2023 18:37:07 UTC (10,811 KB)"
"107","A Linear Parameter-Varying Approach to Data Predictive Control","Chris Verhoek, Julian Berberich, Sofie Haesaert, Roland Tóth, Hossam S. Abbas","Systems and Control (eess.SY)","By means of the linear parameter-varying (LPV) Fundamental Lemma, we derive novel data-driven predictive control (DPC) methods for LPV systems. In particular, we present output-feedback and state-feedback-based LPV-DPC methods with terminal ingredients, which guarantee exponential stability and recursive feasibility. We provide methods for the data-based computation of these terminal ingredients. Furthermore, an in-depth analysis of the properties and implementation aspects of the LPV-DPC schemes is given, including alternative recursive formulations, application for nonlinear systems and handling noise-disturbed data. We demonstrate the performance of the proposed methods on a simulation example involving a nonlinear unbalanced disc system.","Mon, 13 Nov 2023 08:12:28 UTC (2,447 KB)"
"108","Aria-NeRF: Multimodal Egocentric View Synthesis","Jiankai Sun, Jianing Qiu, Chuanyang Zheng, John Tucker, Javier Yu, Mac Schwager","Computer Vision and Pattern Recognition (cs.CV)","We seek to accelerate research in developing rich, multimodal scene models trained from egocentric data, based on differentiable volumetric ray-tracing inspired by Neural Radiance Fields (NeRFs). The construction of a NeRF-like model from an egocentric image sequence plays a pivotal role in understanding human behavior and holds diverse applications within the realms of VR/AR. Such egocentric NeRF-like models may be used as realistic simulations, contributing significantly to the advancement of intelligent agents capable of executing tasks in the real-world. The future of egocentric view synthesis may lead to novel environment representations going beyond today's NeRFs by augmenting visual data with multimodal sensors such as IMU for egomotion tracking, audio sensors to capture surface texture and human language context, and eye-gaze trackers to infer human attention patterns in the scene. To support and facilitate the development and evaluation of egocentric multimodal scene modeling, we present a comprehensive multimodal egocentric video dataset. This dataset offers a comprehensive collection of sensory data, featuring RGB images, eye-tracking camera footage, audio recordings from a microphone, atmospheric pressure readings from a barometer, positional coordinates from GPS, connectivity details from Wi-Fi and Bluetooth, and information from dual-frequency IMU datasets (1kHz and 800Hz) paired with a magnetometer. The dataset was collected with the Meta Aria Glasses wearable device platform. The diverse data modalities and the real-world context captured within this dataset serve as a robust foundation for furthering our understanding of human behavior and enabling more immersive and intelligent experiences in the realms of VR, AR, and robotics.","Sat, 11 Nov 2023 01:56:35 UTC (40,032 KB)"
"109","Bayesian Tensor Factorisations for Time Series of Counts","Zhongzhen Wang, Petros Dellaportas, Ioannis Kosmidis","Methodology (stat.ME)","We propose a flexible nonparametric Bayesian modelling framework for multivariate time series of count data based on tensor factorisations. Our models can be viewed as infinite state space Markov chains of known maximal order with non-linear serial dependence through the introduction of appropriate latent variables. Alternatively, our models can be viewed as Bayesian hierarchical models with conditionally independent Poisson distributed observations. Inference about the important lags and their complex interactions is achieved via MCMC. When the observed counts are large, we deal with the resulting computational complexity of Bayesian inference via a two-step inferential strategy based on an initial analysis of a training set of the data. Our methodology is illustrated using simulation experiments and analysis of real-world data.","Fri, 10 Nov 2023 14:20:53 UTC (542 KB)"
"110","Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education","Mei Tan, Hansol Lee, Dakuo Wang, Hariharan Subramonyam","Computers and Society (cs.CY)","Despite the promises of ML in education, its adoption in the classroom has surfaced numerous issues regarding fairness, accountability, and transparency, as well as concerns about data privacy and student consent. A root cause of these issues is the lack of understanding of the complex dynamics of education, including teacher-student interactions, collaborative learning, and classroom environment. To overcome these challenges and fully utilize the potential of ML in education, software practitioners need to work closely with educators and students to fully understand the context of the data (the backbone of ML applications) and collaboratively define the ML data specifications. To gain a deeper understanding of such a collaborative process, we conduct ten co-design sessions with ML software practitioners, educators, and students. In the sessions, teachers and students work with ML engineers, UX designers, and legal practitioners to define dataset characteristics for a given ML application. We find that stakeholders contextualize data based on their domain and procedural knowledge, proactively design data requirements to mitigate downstream harms and data reliability concerns, and exhibit role-based collaborative strategies and contribution patterns. Further, we find that beyond a seat at the table, meaningful stakeholder participation in ML requires structured supports: defined processes for continuous iteration and co-evaluation, shared contextual data quality standards, and information scaffolds for both technical and non-technical stakeholders to traverse expertise boundaries.","Thu, 9 Nov 2023 23:51:08 UTC (1,872 KB)"
"111","Uncertainty Wrapper in the medical domain: Establishing transparent uncertainty quantification for opaque machine learning models in practice","Lisa Jöckel, Michael Kläs, Georg Popp, Nadja Hilger, Stephan Fricke","Machine Learning (cs.LG)","When systems use data-based models that are based on machine learning (ML), errors in their results cannot be ruled out. This is particularly critical if it remains unclear to the user how these models arrived at their decisions and if errors can have safety-relevant consequences, as is often the case in the medical field. In such cases, the use of dependable methods to quantify the uncertainty remaining in a result allows the user to make an informed decision about further usage and draw possible conclusions based on a given result. This paper demonstrates the applicability and practical utility of the Uncertainty Wrapper using flow cytometry as an application from the medical field that can benefit from the use of ML models in conjunction with dependable and transparent uncertainty quantification.","Thu, 9 Nov 2023 09:58:02 UTC (1,123 KB)"
"112","Learning to Control under Uncertainty with Data-Based Iterative Linear Quadratic Regulator","Ran Wang, Raman Goyal, Suman Chakravorty","Robotics (cs.RO)","This paper studies the learning-to-control problem under process and sensing uncertainties for dynamical systems. In our previous work, we developed a data-based generalization of the iterative linear quadratic regulator (iLQR) to design closed-loop feedback control for high-dimensional dynamical systems with partial state observation. This method required perfect simulation rollouts which are not realistic in real applications. In this work, we briefly introduce this method and explore its efficacy under process and sensing uncertainties. We prove that in the fully observed case where the system dynamics are corrupted with noise but the measurements are perfect, it still converges to the global minimum. However, in the partially observed case where both process and measurement noise exist in the system, this method converges to a biased ""optimum"". Thus multiple rollouts need to be averaged to retrieve the true optimum. The analysis is verified in two nonlinear robotic examples simulated in the above cases.","Wed, 8 Nov 2023 17:39:07 UTC (987 KB)"
"113","Quick Guides for Use of the CompOSE Data Base","Veronica Dexheimer, Marco Mancini, Micaela Oertel, Constanca Providencia, Laura Tolos, Stefan Typel","Nuclear Theory (nucl-th)","We present a combination of two quick guides aimed at summarizing relevant information about the CompOSE nuclear equation of state repository. The first is aimed at nuclear physicists and describes how to provide standard equation of state tables. The second quick guide is meant for users and describes the basic procedures to obtain customized tables with equation of state data. Several examples are included to help providers and users to understand and benefit from the CompOSE database.","Wed, 8 Nov 2023 14:42:00 UTC (2,102 KB)"
"114","Modeling and Control of Diesel Engine Emissions using Multi-layer Neural Networks and Economic Model Predictive Control","Jiadi Zhang, Xiao Li, Mohammad Reza Amini, Ilya Kolmanovsky, Munechika Tsutsumi, Hayato Nakada","Systems and Control (eess.SY)","This paper presents the results of developing a multi-layer Neural Network (NN) to represent diesel engine emissions and integrating this NN into control design. Firstly, a NN is trained and validated to simultaneously predict oxides of nitrogen (N Ox) and Soot using both transient and steady-state data. Based on the input-output correlation analysis, inputs to NN with the highest influence on the emissions are selected while keeping the NN structure simple. Secondly, a co-simulation framework is implemented to integrate the NN emissions model with a model of a diesel engine airpath system built in GT-Power and used to identify a low-order linear parameter-varying (LPV) model for emissions prediction. Finally, an economic supervisory model predictive controller (MPC) is developed using the LPV emissions model to adjust setpoints to an inner-loop airpath tracking MPC. Simulation results are reported illustrating the capability of the resulting controller to reduce N Ox, meet the target Soot limit, and track the adjusted intake manifold pressure and exhaust gas recirculation (EGR) rate targets.","Mon, 6 Nov 2023 21:41:26 UTC (1,730 KB)"
"115","Persistent homology for high-dimensional data based on spectral methods","Sebastian Damrich, Philipp Berens, Dmitry Kobak","Machine Learning (cs.LG)","Persistent homology is a popular computational tool for detecting non-trivial topology of point clouds, such as the presence of loops or voids. However, many real-world datasets with low intrinsic dimensionality reside in an ambient space of much higher dimensionality. We show that in this case vanilla persistent homology becomes very sensitive to noise and fails to detect the correct topology. The same holds true for most existing refinements of persistent homology. As a remedy, we find that spectral distances on the $k$-nearest-neighbor graph of the data, such as diffusion distance and effective resistance, allow persistent homology to detect the correct topology even in the presence of high-dimensional noise. Furthermore, we derive a novel closed-form expression for effective resistance in terms of the eigendecomposition of the graph Laplacian, and describe its relation to diffusion distances. Finally, we apply these methods to several high-dimensional single-cell RNA-sequencing datasets and show that spectral distances on the $k$-nearest-neighbor graph allow robust detection of cell cycle loops.","Mon, 6 Nov 2023 13:18:08 UTC (1,611 KB)"
"116","Machine learning-based photometric classification of galaxies, quasars, emission-line galaxies, and stars","Fatemeh Zahra Zeraatgari, Fatemeh Hafezianzade, Yanxia Zhang, Liquan Mei, Ashraf Ayubinia, Amin Mosallanezhad, Jingyi Zhang","Astrophysics of Galaxies (astro-ph.GA)","This paper explores the application of machine learning methods for classifying astronomical sources using photometric data, including normal and emission line galaxies (ELGs; starforming, starburst, AGN, broad line), quasars, and stars. We utilized samples from Sloan Digital Sky Survey (SDSS) Data Release 17 (DR17) and the ALLWISE catalog, which contain spectroscopically labeled sources from SDSS. Our methodology comprises two parts. First, we conducted experiments, including three-class, four-class, and seven-class classifications, employing the Random Forest (RF) algorithm. This phase aimed to achieve optimal performance with balanced datasets. In the second part, we trained various machine learning methods, such as $k$-nearest neighbors (KNN), RF, XGBoost (XGB), voting, and artificial neural network (ANN), using all available data based on promising results from the first phase. Our results highlight the effectiveness of combining optical and infrared features, yielding the best performance across all classifiers. Specifically, in the three-class experiment, RF and XGB algorithms achieved identical average F1 scores of 98.93 per~cent on both balanced and unbalanced datasets. In the seven-class experiment, our average F1 score was 73.57 per~cent. Using the XGB method in the four-class experiment, we achieved F1 scores of 87.9 per~cent for normal galaxies (NGs), 81.5 per~cent for ELGs, 99.1 per~cent for stars, and 98.5 per~cent for quasars (QSOs). Unlike classical methods based on time-consuming spectroscopy, our experiments demonstrate the feasibility of using automated algorithms on carefully classified photometric data. With more data and ample training samples, detailed photometric classification becomes possible, aiding in the selection of follow-up observation candidates.","Mon, 6 Nov 2023 08:37:02 UTC (10,741 KB)"
"117","Obtaining Explainable Classification Models using Distributionally Robust Optimization","Sanjeeb Dash, Soumyadip Ghosh, Joao Goncalves, Mark S. Squillante","Machine Learning (stat.ML)","Model explainability is crucial for human users to be able to interpret how a proposed classifier assigns labels to data based on its feature values. We study generalized linear models constructed using sets of feature value rules, which can capture nonlinear dependencies and interactions. An inherent trade-off exists between rule set sparsity and its prediction accuracy. It is computationally expensive to find the right choice of sparsity -- e.g., via cross-validation -- with existing methods. We propose a new formulation to learn an ensemble of rule sets that simultaneously addresses these competing factors. Good generalization is ensured while keeping computational costs low by utilizing distributionally robust optimization. The formulation utilizes column generation to efficiently search the space of rule sets and constructs a sparse ensemble of rule sets, in contrast with techniques like random forests or boosting and their variants. We present theoretical results that motivate and justify the use of our distributionally robust formulation. Extensive numerical experiments establish that our method improves over competing methods -- on a large set of publicly available binary classification problem instances -- with respect to one or more of the following metrics: generalization quality, computational cost, and explainability.","Fri, 3 Nov 2023 15:45:34 UTC (55 KB)"
"118","Subgroup identification using individual participant data from multiple trials on low back pain","Cynthia Huber, Tim Friede","Methodology (stat.ME)","Model-based recursive partitioning (MOB) and its extension, metaMOB, are potent tools for identifying subgroups with differential treatment effects. In the metaMOB approach random effects are used to model heterogeneity of the treatment effects when pooling data from various trials. In situations where interventions offer only small overall benefits and require extensive, costly trials with a large participant enrollment, leveraging individual-participant data (IPD) from multiple trials can help identify individuals who are most likely to benefit from the intervention. We explore the application of MOB and metaMOB in the context of non specific low back pain treatment, using synthesized data based on a subset of the individual participant data meta-analysis by Patel et al. Our study underscores the need to explore heterogeneity in intercepts and treatment effects to identify subgroups with differential treatment effects in IPD meta-analyses.","Thu, 2 Nov 2023 15:25:11 UTC (1,477 KB)"
"119","Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop Simulation","Jay Sarva, Jingkang Wang, James Tu, Yuwen Xiong, Sivabalan Manivasagam, Raquel Urtasun","Robotics (cs.RO)","Self-driving vehicles (SDVs) must be rigorously tested on a wide range of scenarios to ensure safe deployment. The industry typically relies on closed-loop simulation to evaluate how the SDV interacts on a corpus of synthetic and real scenarios and verify it performs properly. However, they primarily only test the system's motion planning module, and only consider behavior variations. It is key to evaluate the full autonomy system in closed-loop, and to understand how variations in sensor data based on scene appearance, such as the shape of actors, affect system performance. In this paper, we propose a framework, Adv3D, that takes real world scenarios and performs closed-loop sensor simulation to evaluate autonomy performance, and finds vehicle shapes that make the scenario more challenging, resulting in autonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add contrived adversarial shapes to vehicle roof-tops or roadside to harm perception only, we optimize a low-dimensional shape representation to modify the vehicle shape itself in a realistic manner to degrade autonomy performance (e.g., perception, prediction, and motion planning). Moreover, we find that the shape variations found with Adv3D optimized in closed-loop are much more effective than those in open-loop, demonstrating the importance of finding scene appearance variations that affect autonomy in the interactive setting.","Thu, 2 Nov 2023 17:56:44 UTC (7,973 KB)"
"120","Direct System Identification of Dynamical Networks with Partial Measurements: a Maximum Likelihood Approach","João Victor Galvão da Mata, Anders Hansson, Martin S. Andersen","Systems and Control (eess.SY)","This paper introduces a novel direct approach to system identification of dynamic networks with missing data based on maximum likelihood estimation. Dynamic networks generally present a singular probability density function, which poses a challenge in the estimation of their parameters. By leveraging knowledge about the network's interconnections, we show that it is possible to transform the problem into more tractable form by applying linear transformations. This results in a nonsingular probability density function, enabling the application of maximum likelihood estimation techniques. Our preliminary numerical results suggest that when combined with global optimization algorithms or a suitable initialization strategy, we are able to obtain a good estimate the dynamic of the internal systems.","Wed, 1 Nov 2023 08:46:18 UTC (122 KB)[v2] Fri, 3 Nov 2023 21:55:02 UTC (129 KB)"
"121","Entropy solutions to the fully non-local diffusion equations","Ying Li, Chao Zhang","Analysis of PDEs (math.AP)","We consider the fully non-local diffusion equations with non-negative $L^1$-data. Based on the approximation and energy methods, we prove the existence and uniqueness of non-negative entropy solutions for such problems. In particular, our results are valid for the time-space fractional Laplacian equations.","Wed, 1 Nov 2023 07:43:41 UTC (21 KB)"
"122","MMM and MMMSynth: Clustering of heterogeneous tabular data, and synthetic data generation","Chandrani Kumari, Rahul Siddharthan","Machine Learning (cs.LG)","We provide new algorithms for two tasks relating to heterogeneous tabular datasets: clustering, and synthetic data generation. Tabular datasets typically consist of heterogeneous data types (numerical, ordinal, categorical) in columns, but may also have hidden cluster structure in their rows: for example, they may be drawn from heterogeneous (geographical, socioeconomic, methodological) sources, such that the outcome variable they describe (such as the presence of a disease) may depend not only on the other variables but on the cluster context. Moreover, sharing of biomedical data is often hindered by patient confidentiality laws, and there is current interest in algorithms to generate synthetic tabular data from real data, for example via deep learning. We demonstrate a novel EM-based clustering algorithm, MMM (``Madras Mixture Model''), that outperforms standard algorithms in determining clusters in synthetic heterogeneous data, and recovers structure in real data. Based on this, we demonstrate a synthetic tabular data generation algorithm, MMMsynth, that pre-clusters the input data, and generates cluster-wise synthetic data assuming cluster-specific data distributions for the input columns. We benchmark this algorithm by testing the performance of standard ML algorithms when they are trained on synthetic data and tested on real published datasets. Our synthetic data generation algorithm outperforms other literature tabular-data generators, and approaches the performance of training purely with real data.","Mon, 30 Oct 2023 11:26:01 UTC (1,507 KB)"
"123","Efficient Test-Time Adaptation for Super-Resolution with Second-Order Degradation and Reconstruction","Zeshuai Deng, Zhuokun Chen, Shuaicheng Niu, Thomas H. Li, Bohan Zhuang, Mingkui Tan","Computer Vision and Pattern Recognition (cs.CV)","Image super-resolution (SR) aims to learn a mapping from low-resolution (LR) to high-resolution (HR) using paired HR-LR training images. Conventional SR methods typically gather the paired training data by synthesizing LR images from HR images using a predetermined degradation model, e.g., Bicubic down-sampling. However, the realistic degradation type of test images may mismatch with the training-time degradation type due to the dynamic changes of the real-world scenarios, resulting in inferior-quality SR images. To address this, existing methods attempt to estimate the degradation model and train an image-specific model, which, however, is quite time-consuming and impracticable to handle rapidly changing domain shifts. Moreover, these methods largely concentrate on the estimation of one degradation type (e.g., blur degradation), overlooking other degradation types like noise and JPEG in real-world test-time scenarios, thus limiting their practicality. To tackle these problems, we present an efficient test-time adaptation framework for SR, named SRTTA, which is able to quickly adapt SR models to test domains with different/unknown degradation types. Specifically, we design a second-order degradation scheme to construct paired data based on the degradation type of the test image, which is predicted by a pre-trained degradation classifier. Then, we adapt the SR model by implementing feature-level reconstruction learning from the initial test image to its second-order degraded counterparts, which helps the SR model generate plausible HR images. Extensive experiments are conducted on newly synthesized corrupted DIV2K datasets with 8 different degradations and several real-world datasets, demonstrating that our SRTTA framework achieves an impressive improvement over existing methods with satisfying speed. The source code is available at this https URL.","Sun, 29 Oct 2023 13:58:57 UTC (2,663 KB)"
"124","Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation","Kunlin Cai, Jinghuai Zhang, Will Shand, Zhiqing Hong, Guang Wang, Desheng Zhang, Jianfeng Chi, Yuan Tian","Machine Learning (cs.LG)","As location-based services (LBS) have grown in popularity, the collection of human mobility data has become increasingly extensive to build machine learning (ML) models offering enhanced convenience to LBS users. However, the convenience comes with the risk of privacy leakage since this type of data might contain sensitive information related to user identities, such as home/work locations. Prior work focuses on protecting mobility data privacy during transmission or prior to release, lacking the privacy risk evaluation of mobility data-based ML models. To better understand and quantify the privacy leakage in mobility data-based ML models, we design a privacy attack suite containing data extraction and membership inference attacks tailored for point-of-interest (POI) recommendation models, one of the most widely used mobility data-based ML models. These attacks in our attack suite assume different adversary knowledge and aim to extract different types of sensitive information from mobility data, providing a holistic privacy risk assessment for POI recommendation models. Our experimental evaluation using two real-world mobility datasets demonstrates that current POI recommendation models are vulnerable to our attacks. We also present unique findings to understand what types of mobility data are more susceptible to privacy attacks. Finally, we evaluate defenses against these attacks and highlight future directions and challenges.","Sat, 28 Oct 2023 06:17:52 UTC (3,575 KB)"
"125","Interpretable machine learning for finding intermediate-mass black holes","Mario Pasquato, Piero Trevisan, Abbas Askar, Pablo Lemos, Gaia Carenini, Michela Mapelli, Yashar Hezaveh","Astrophysics of Galaxies (astro-ph.GA)","Definitive evidence that globular clusters (GCs) host intermediate-mass black holes (IMBHs) is elusive. Machine learning (ML) models trained on GC simulations can in principle predict IMBH host candidates based on observable features. This approach has two limitations: first, an accurate ML model is expected to be a black box due to complexity; second, despite our efforts to realistically simulate GCs, the simulation physics or initial conditions may fail to fully reflect reality. Therefore our training data may be biased, leading to a failure in generalization on observational data. Both the first issue -- explainability/interpretability -- and the second -- out of distribution generalization and fairness -- are active areas of research in ML. Here we employ techniques from these fields to address them: we use the anchors method to explain an XGBoost classifier; we also independently train a natively interpretable model using Certifiably Optimal RulE ListS (CORELS). The resulting model has a clear physical meaning, but loses some performance with respect to XGBoost. We evaluate potential candidates in real data based not only on classifier predictions but also on their similarity to the training data, measured by the likelihood of a kernel density estimation model. This measures the realism of our simulated data and mitigates the risk that our models may produce biased predictions by working in extrapolation. We apply our classifiers to real GCs, obtaining a predicted classification, a measure of the confidence of the prediction, an out-of-distribution flag, a local rule explaining the prediction of XGBoost and a global rule from CORELS.","Sat, 28 Oct 2023 02:15:09 UTC (17,406 KB)"
"126","Temperature Monitoring of Agricultural Areas in a Secure Data Room","Thomas Ederer, Martin Ivancsits, Igor Ivkić","Computers and Society (cs.CY)","Agricultural production is highly dependent on naturally occurring environmental conditions like change of seasons and the weather. Especially in fruit and wine growing, late frosts occurring shortly after the crops have sprouted have the potential to cause massive damage to plants [L1,L2] [1]. In this article we present a cost-efficient temperature monitoring system for detecting and reacting to late frosts to prevent crop failures. The proposed solution includes a data space where Internet of Things (IoT) devices can form a cyber-physical system (CPS) to interact with their nearby environment and securely exchange data. Based on this data, more accurate predictions can be made in the future using machine learning (ML), which will further contribute to minimising economic damage caused by crop failures.","Fri, 27 Oct 2023 09:49:52 UTC (314 KB)"
"127","Neural style transfer of weak lensing mass maps","Masato Shirasaki, Shiro Ikeda","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","We propose a new generative model of projected cosmic mass density maps inferred from weak gravitational lensing observations of distant galaxies (weak lensing mass maps). We construct the model based on a neural style transfer so that it can transform Gaussian weak lensing mass maps into deeply non-Gaussian counterparts as predicted in ray-tracing lensing simulations. We develop an unpaired image-to-image translation method with Cycle-Consistent Generative Adversarial Networks (Cycle GAN), which learn efficient mapping from an input domain to a target domain. Our model is designed to enjoy important advantages; it is trainable with no need for paired simulation data, flexible to make the input domain visually meaningful, and expandable to rapidly-produce a map with a larger sky coverage than training data without additional learning. Using 10,000 lensing simulations, we find that appropriate labeling of training data based on field variance requires the model to exhibit a desired diversity of various summary statistics for weak lensing mass maps. Compared with a popular log-normal model, our model improves in predicting the statistical natures of three-point correlations and local properties of rare high-density regions. We also demonstrate that our model enables us to produce a continuous map with a sky coverage of $\sim166\, \mathrm{deg}^2$ but similar non-Gaussian features to training data covering $\sim12\, \mathrm{deg}^2$ in a GPU minute. Hence, our model can be beneficial to massive productions of synthetic weak lensing mass maps, which is of great importance in future precise real-world analyses.","Thu, 26 Oct 2023 04:25:41 UTC (1,851 KB)"
"128","Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning","Ananth Balashankar, Xiao Ma, Aradhana Sinha, Ahmad Beirami, Yao Qin, Jilin Chen, Alex Beutel","Machine Learning (cs.LG)","As large language models (LLMs) are widely adopted, new safety issues and policies emerge, to which existing safety classifiers do not generalize well. If we have only observed a few examples of violations of a new safety rule, how can we build a classifier to detect violations? In this paper, we study the novel setting of domain-generalized few-shot learning for LLM-based text safety classifiers. Unlike prior few-shot work, these new safety issues can be hard to uncover and we do not get to choose the few examples. We demonstrate that existing few-shot techniques do not perform well in this setting, and rather we propose to do parameter-efficient fine-tuning (PEFT) combined with augmenting training data based on similar examples in prior existing rules. We empirically show that our approach of similarity-based data-augmentation + prompt-tuning (DAPT) consistently outperforms baselines that either do not rely on data augmentation or on PEFT by 7-17% F1 score in the Social Chemistry moral judgement and 9-13% AUC in the Toxicity detection tasks, even when the new rule is loosely correlated with existing ones.","Wed, 25 Oct 2023 19:57:07 UTC (7,284 KB)"
"129","Joint Constraints on the Hubble Constant, Spatial Curvature, and Sound Horizon from the Late-time Universe with Cosmography","Kaituo Zhang, Tianyao Zhou, Bing Xu, Qihong Huang, Yangsheng Yuan","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","In this paper, using the latest Pantheon+ sample of Type Ia supernovae (SNe Ia), Baryon Acoustic Oscillation (BAO) measurements, and observational Hubble data (OHD), we carry out a joint constraint on the Hubble constant $H_0$, the spatial curvature $\Omega_{\rm K}$, and the sound horizon at the end of drag epoch $r_{\rm d}$. To be model-independent, four cosmography models, i.e., the Taylor series in terms of redshift $y_1=z/(1+z)$, $y_2=\arctan(z)$, $y_3=\ln(1+z)$, and the Padé approximants, are used without the assumption of flat Universe. The results show that the $H_0$ is anti-correlated with $\Omega_{\rm K}$ and $r_{\rm d}$, indicating smaller $\Omega_{\rm K}$ or $r_{\rm d}$ would be helpful in alleviating the Hubble tension. And the values of $H_0$ and $r_{\rm d}$ are consistent with the estimate derived from the Planck Cosmic Microwave Background (CMB) data based on the flat $\Lambda$CDM model, but $H_0$ is in 2.3$\sim$3.0$\sigma$ tension with that obtained by \cite{Riess2022} in all these cosmographic approaches. Meanwhile, a flat Universe is preferred by the present observations under all approximations except the third order of $y_1$ and $y_2$ of the Taylor series. Furthermore, according to the values of the Bayesian evidence, we found that the flat $\Lambda$CDM remains to be the most favored model by the joint datasets, and the Padé approximant of order (2,2), the third order of $y_3$ and $y_1$ are the top three cosmographic expansions that fit the datasets best, while the Taylor series in terms of $y_2$ are essentially ruled out.","Wed, 25 Oct 2023 10:02:48 UTC (2,151 KB)[v2] Thu, 23 Nov 2023 12:39:17 UTC (2,151 KB)"
"130","Facial Data Minimization: Shallow Model as Your Privacy Filter","Yuwen Pu, Jiahao Chen, Jiayu Pan, Hao li, Diqun Yan, Xuhong Zhang, Shouling Ji","Cryptography and Security (cs.CR)","Face recognition service has been used in many fields and brings much convenience to people. However, once the user's facial data is transmitted to a service provider, the user will lose control of his/her private data. In recent years, there exist various security and privacy issues due to the leakage of facial data. Although many privacy-preserving methods have been proposed, they usually fail when they are not accessible to adversaries' strategies or auxiliary data. Hence, in this paper, by fully considering two cases of uploading facial images and facial features, which are very typical in face recognition service systems, we proposed a data privacy minimization transformation (PMT) method. This method can process the original facial data based on the shallow model of authorized services to obtain the obfuscated data. The obfuscated data can not only maintain satisfactory performance on authorized models and restrict the performance on other unauthorized models but also prevent original privacy data from leaking by AI methods and human visual theft. Additionally, since a service provider may execute preprocessing operations on the received data, we also propose an enhanced perturbation method to improve the robustness of PMT. Besides, to authorize one facial image to multiple service models simultaneously, a multiple restriction mechanism is proposed to improve the scalability of PMT. Finally, we conduct extensive experiments and evaluate the effectiveness of the proposed PMT in defending against face reconstruction, data abuse, and face attribute estimation attacks. These experimental results demonstrate that PMT performs well in preventing facial data abuse and privacy leakage while maintaining face recognition accuracy.","Tue, 24 Oct 2023 07:54:39 UTC (6,338 KB)[v2] Sun, 12 Nov 2023 10:10:24 UTC (6,257 KB)"
"131","Domain Terminology Integration into Machine Translation: Leveraging Large Language Models","Yasmin Moslem, Gianfranco Romani, Mahdi Molaei, Rejwanul Haque, John D. Kelleher, Andy Way","Computation and Language (cs.CL)","This paper discusses the methods that we used for our submissions to the WMT 2023 Terminology Shared Task for German-to-English (DE-EN), English-to-Czech (EN-CS), and Chinese-to-English (ZH-EN) language pairs. The task aims to advance machine translation (MT) by challenging participants to develop systems that accurately translate technical terms, ultimately enhancing communication and understanding in specialised domains. To this end, we conduct experiments that utilise large language models (LLMs) for two purposes: generating synthetic bilingual terminology-based data, and post-editing translations generated by an MT model through incorporating pre-approved terms. Our system employs a four-step process: (i) using an LLM to generate bilingual synthetic data based on the provided terminology, (ii) fine-tuning a generic encoder-decoder MT model, with a mix of the terminology-based synthetic data generated in the first step and a randomly sampled portion of the original generic training data, (iii) generating translations with the fine-tuned MT model, and (iv) finally, leveraging an LLM for terminology-constrained automatic post-editing of the translations that do not include the required terms. The results demonstrate the effectiveness of our proposed approach in improving the integration of pre-approved terms into translations. The number of terms incorporated into the translations of the blind dataset increases from an average of 36.67% with the generic model to an average of 72.88% by the end of the process. In other words, successful utilisation of terms nearly doubles across the three language pairs.","Sun, 22 Oct 2023 23:25:28 UTC (217 KB)"
"132","On the Relationship Between Relevance and Conflict in Online Social Link Recommendations","Yanbang Wang, Jon Kleinberg","Social and Information Networks (cs.SI)","In an online social network, link recommendations are a way for users to discover relevant links to people they may know, thereby potentially increasing their engagement on the platform. However, the addition of links to a social network can also have an effect on the level of conflict in the network -- expressed in terms of polarization and disagreement. To this date, however, we have very little understanding of how these two implications of link formation relate to each other: are the goals of high relevance and conflict reduction aligned, or are the links that users are most likely to accept fundamentally different from the ones with the greatest potential for reducing conflict? Here we provide the first analysis of this question, using the recently popular Friedkin-Johnsen model of opinion dynamics. We first present a surprising result on how link additions shift the level of opinion conflict, followed by explanation work that relates the amount of shift to structural features of the added links. We then characterize the gap in conflict reduction between the set of links achieving the largest reduction and the set of links achieving the highest relevance. The gap is measured on real-world data, based on instantiations of relevance defined by 13 link recommendation algorithms. We find that some, but not all, of the more accurate algorithms actually lead to better reduction of conflict. Our work suggests that social links recommended for increasing user engagement may not be as conflict-provoking as people might have thought.","Sat, 21 Oct 2023 17:52:58 UTC (8,351 KB)[v2] Sat, 9 Dec 2023 17:38:54 UTC (9,136 KB)[v3] Tue, 16 Jan 2024 00:19:07 UTC (9,137 KB)[v4] Wed, 17 Jan 2024 02:45:48 UTC (9,138 KB)"
"133","Physics-informed Neural Network Modelling and Predictive Control of District Heating Systems","Laura Boca de Giuli, Alessio La Bella, Riccardo Scattolini","Systems and Control (eess.SY)","This paper addresses the data-based modelling and optimal control of District Heating Systems (DHSs). Physical models of such large-scale networked systems are governed by complex nonlinear equations that require a large amount of parameters, leading to potential computational issues in optimizing their operation. A novel methodology is hence proposed, exploiting operational data and available physical knowledge to attain accurate and computationally efficient DHSs dynamic models. The proposed idea consists in leveraging multiple Recurrent Neural Networks (RNNs) and in embedding the physical topology of the DHS network in their interconnections. With respect to standard RNN approaches, the resulting modelling methodology, denoted as Physics-Informed RNN (PI-RNN), enables to achieve faster training procedures and higher modelling accuracy, even when reduced-dimension models are exploited. The developed PI-RNN modelling technique paves the way for the design of a Nonlinear Model Predictive Control (NMPC) regulation strategy, enabling, with limited computational time, to minimize production costs, to increase system efficiency and to respect operative constraints over the whole DHS network. The proposed methods are tested in simulation on a DHS benchmark referenced in the literature, showing promising results from the modelling and control perspective.","Sat, 21 Oct 2023 08:20:34 UTC (3,068 KB)"
"134","Exploratory functional data analysis of multivariate densities for the identification of agricultural soil contamination by risk elements","Tomáš Matys Grygar, Una Radojičić, Ivana Pavlů, Sonja Greven, Johanna Genest Nešlehová, Štěpánka Tůmová, Karel Hron","Applications (stat.AP)","Geochemical mapping of risk element concentrations in soils is performed in countries around the world. It results in large datasets of high analytical quality, which can be used to identify soils that violate individual legislative limits for safe food production. However, there is a lack of advanced data mining tools that would be suitable for sensitive exploratory data analysis of big data while respecting the natural variability of soil composition. To distinguish anthropogenic contamination from natural variation, the analysis of the entire data distributions for smaller sub-areas is key. In this article, we propose a new data mining method for geochemical mapping data based on functional data analysis of probability density functions in the framework of Bayes spaces after post-stratification of a big dataset to smaller districts. Proposed tools allow us to analyse the entire distribution, going beyond a superficial detection of extreme concentration anomalies. We illustrate the proposed methodology on a dataset gathered according to the Czech national legislation (1990--2009). Taking into account specific properties of probability density functions and recent results for orthogonal decomposition of multivariate densities enabled us to reveal real contamination patterns that were so far only suspected in Czech agricultural soils. We process the above Czech soil composition dataset by first compartmentalising it into spatial units, in particular the districts, and by subsequently clustering these districts according to diagnostic features of their uni- and multivariate distributions at high concentration ends. Comparison between compartments is key to the reliable distinction of diffuse contamination. In this work, we used soil contamination by Cu-bearing pesticides as an example for empirical testing of the proposed data mining approach.","Fri, 20 Oct 2023 18:48:39 UTC (5,235 KB)[v2] Tue, 24 Oct 2023 08:27:02 UTC (5,235 KB)[v3] Mon, 6 Nov 2023 14:56:32 UTC (5,235 KB)"
"135","Data Augmentations for Improved (Large) Language Model Generalization","Amir Feder, Yoav Wald, Claudia Shi, Suchi Saria, David Blei","Machine Learning (cs.LG)","The reliance of text classifiers on spurious correlations can lead to poor generalization at deployment, raising concerns about their use in safety-critical domains such as healthcare. In this work, we propose to use counterfactual data augmentation, guided by knowledge of the causal structure of the data, to simulate interventions on spurious features and to learn more robust text classifiers. We show that this strategy is appropriate in prediction problems where the label is spuriously correlated with an attribute. Under the assumptions of such problems, we discuss the favorable sample complexity of counterfactual data augmentation, compared to importance re-weighting. Pragmatically, we match examples using auxiliary data, based on diff-in-diff methodology, and use a large language model (LLM) to represent a conditional probability of text. Through extensive experimentation on learning caregiver-invariant predictors of clinical diagnoses from medical narratives and on semi-synthetic data, we demonstrate that our method for simulating interventions improves out-of-distribution (OOD) accuracy compared to baseline invariant learning algorithms.","Thu, 19 Oct 2023 14:59:25 UTC (485 KB)[v2] Tue, 9 Jan 2024 17:46:22 UTC (508 KB)"
"136","Self-triggered Consensus Control of Multi-agent Systems from Data","Yifei Li, Xin Wang, Jian Sun, Gang Wang, Jie Chen","Systems and Control (eess.SY)","This paper considers self-triggered consensus control of unknown linear multi-agent systems (MASs). Self-triggering mechanisms (STMs) are widely used in MASs, thanks to their advantages in avoiding continuous monitoring and saving computing and communication resources. However, existing results require the knowledge of system matrices, which are difficult to obtain in real-world settings. To address this challenge, we present a data-driven approach to designing STMs for unknown MASs building upon the model-based solutions. Our approach leverages a system lifting method, which allows us to derive a data-driven representation for the MAS. Subsequently, a data-driven self-triggered consensus control (STC) scheme is designed, which combines a data-driven STM with a state feedback control law. We establish a data-based stability criterion for asymptotic consensus of the closed-loop MAS in terms of linear matrix inequalities, whose solution provides a matrix for the STM as well as a stabilizing controller gain. In the presence of external disturbances, a model-based STC scheme is put forth for $\mathcal{H}_{\infty}$-consensus of MASs, serving as a baseline for the data-driven STC. Numerical tests are conducted to validate the correctness of the data- and model-based STC approaches. Our data-driven approach demonstrates a superior trade-off between control performance and communication efficiency from finite, noisy data relative to the system identification-based one.","Thu, 19 Oct 2023 14:51:15 UTC (4,889 KB)"
"137","Revisiting Sparse Retrieval for Few-shot Entity Linking","Yulin Chen, Zhenran Xu, Baotian Hu, Min Zhang","Computation and Language (cs.CL)","Entity linking aims to link ambiguous mentions to their corresponding entities in a knowledge base. One of the key challenges comes from insufficient labeled data for specific domains. Although dense retrievers have achieved excellent performance on several benchmarks, their performance decreases significantly when only a limited amount of in-domain labeled data is available. In such few-shot setting, we revisit the sparse retrieval method, and propose an ELECTRA-based keyword extractor to denoise the mention context and construct a better query expression. For training the extractor, we propose a distant supervision method to automatically generate training data based on overlapping tokens between mention contexts and entity descriptions. Experimental results on the ZESHEL dataset demonstrate that the proposed method outperforms state-of-the-art models by a significant margin across all test domains, showing the effectiveness of keyword-enhanced sparse retrieval.","Thu, 19 Oct 2023 03:51:10 UTC (174 KB)"
"138","A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model","Eric Petermann, Peter Bossew, Joachim Kemski, Valeria Gruber, Nils Suhr, Bernd Hoffmann","Machine Learning (stat.ML)","Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor radon exposure at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow exposure estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. We applied a two-stage modelling approach: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and population weighting of floor-level predictions. In this way, the uncertainty of the individual predictions is effectively propagated into the estimate of variability at the aggregated level. The results give an arithmetic mean of 63 Bq/m3, a geometric mean of 41 Bq/m3 and a 95 %ile of 180 Bq/m3. The exceedance probability for 100 Bq/m3 and 300 Bq/m3 are 12.5 % (10.5 million people) and 2.2 % (1.9 million people), respectively. In large cities, individual indoor radon exposure is generally lower than in rural areas, which is a due to the different distribution of the population on floor levels. The advantages of our approach are 1) an accurate exposure estimation even if the survey was not fully representative with respect to the main controlling factors, and 2) an estimate of the exposure distribution with a much higher spatial resolution than basic descriptive statistics.","Tue, 17 Oct 2023 10:51:05 UTC (2,942 KB)"
"139","SODA: Robust Training of Test-Time Data Adaptors","Zige Wang, Yonggang Zhang, Zhen Fang, Long Lan, Wenjing Yang, Bo Han","Machine Learning (cs.LG)","Adapting models deployed to test distributions can mitigate the performance degradation caused by distribution shifts. However, privacy concerns may render model parameters inaccessible. One promising approach involves utilizing zeroth-order optimization (ZOO) to train a data adaptor to adapt the test data to fit the deployed models. Nevertheless, the data adaptor trained with ZOO typically brings restricted improvements due to the potential corruption of data features caused by the data adaptor. To address this issue, we revisit ZOO in the context of test-time data adaptation. We find that the issue directly stems from the unreliable estimation of the gradients used to optimize the data adaptor, which is inherently due to the unreliable nature of the pseudo-labels assigned to the test data. Based on this observation, we propose pseudo-label-robust data adaptation (SODA) to improve the performance of data adaptation. Specifically, SODA leverages high-confidence predicted labels as reliable labels to optimize the data adaptor with ZOO for label prediction. For data with low-confidence predictions, SODA encourages the adaptor to preserve data information to mitigate data corruption. Empirical results indicate that SODA can significantly enhance the performance of deployed models in the presence of distribution shifts without requiring access to model parameters.","Tue, 17 Oct 2023 09:22:20 UTC (547 KB)"
"140","Population-based wind farm monitoring based on a spatial autoregressive approach","W. Lin, K. Worden, E.J. Cross","Machine Learning (cs.LG)","An important challenge faced by wind farm operators is to reduce operation and maintenance cost. Structural health monitoring provides a means of cost reduction through minimising unnecessary maintenance trips as well as prolonging turbine service life. Population-based structural health monitoring can further reduce the cost of health monitoring systems by implementing one system for multiple structures (i.e.~turbines). At the same time, shared data within a population of structures may improve the predictions of structural behaviour. To monitor turbine performance at a population/farm level, an important initial step is to construct a model that describes the behaviour of all turbines under normal conditions. This paper proposes a population-level model that explicitly captures the spatial and temporal correlations (between turbines) induced by the wake effect. The proposed model is a Gaussian process-based spatial autoregressive model, named here a GP-SPARX model. This approach is developed since (a) it reflects our physical understanding of the wake effect, and (b) it benefits from a stochastic data-based learner. A case study is provided to demonstrate the capability of the GP-SPARX model in capturing spatial and temporal variations as well as its potential applicability in a health monitoring system.","Mon, 16 Oct 2023 16:26:40 UTC (2,751 KB)"
"141","Group-Orthogonal Subsampling for Hierarchical Data Based on Linear Mixed Models","Jiaqing Zhu, Lin Wang, Fasheng Sun","Methodology (stat.ME)","Hierarchical data analysis is crucial in various fields for making discoveries. The linear mixed model is often used for training hierarchical data, but its parameter estimation is computationally expensive, especially with big data. Subsampling techniques have been developed to address this challenge. However, most existing subsampling methods assume homogeneous data and do not consider the possible heterogeneity in hierarchical data. To address this limitation, we develop a new approach called group-orthogonal subsampling (GOSS) for selecting informative subsets of hierarchical data that may exhibit heterogeneity. GOSS selects subdata with balanced data size among groups and combinatorial orthogonality within each group, resulting in subdata that are $D$- and $A$-optimal for building linear mixed models. Estimators of parameters trained on GOSS subdata are consistent and asymptotically normal. GOSS is shown to be numerically appealing via simulations and a real data application. Theoretical proofs, R codes, and supplementary numerical results are accessible online as Supplementary Materials.","Mon, 16 Oct 2023 04:25:07 UTC (652 KB)"
"142","Evaluating residual acceleration noise for TianQin gravitational waves observatory with an empirical magnetic field model","Wei Su, Ze-Bing Zhou, Yan Wang, Chen Zhou, P. F. Chen, Wei Hong, J. H. Peng, Yun Yang, Y. W. Ni","Instrumentation and Methods for Astrophysics (astro-ph.IM)","TianQin (TQ) project plans to deploy three satellites in space around the Earth to measure the displacement change of test masses caused by gravitational waves via laser interferometry. The requirement of the acceleration noise of the test mass is on the order of $10^{-15}~\,{\rm m}\,{\rm s}^{-2}\,{\rm Hz}^{-1/2}$ in the sensitive frequency range of TQ, %the extremely precise acceleration measurement requirements make it necessary to investigate acceleration noise due to space magnetic fields. which is so stringent that the acceleration noise caused by the interaction of the space magnetic field with the test mass needs to be investigated. In this work, by using the Tsyganenko model, a data-based empirical space magnetic field model, we obtain the magnetic field distribution around TQ's orbit spanning two solar cycles in 23 years from 1998 to 2020. With the obtained space magnetic field, we derive the distribution and amplitude spectral densities (ASDs) of the acceleration noise of TQ in 23 years. Our results reveal that the average values of the ratio of the acceleration noise cauesd by the space magnetic field to the requirements of TQ at 1 mHz ($R_{\rm 1mHz}$) and 6 mHz ($R_{\rm 6mHz}$) are 0.123$\pm$0.052 and 0.027$\pm$0.013, respectively. The occurence probabilities of $R_{\rm 1mHz}>0.2$ and $>0.3$ are only 7.9% and 1.2%, respectively, and $R_{\rm 6mHz}$ never exceeds 0.2.","Mon, 16 Oct 2023 03:59:51 UTC (8,157 KB)[v2] Mon, 27 Nov 2023 04:01:44 UTC (4,078 KB)[v3] Thu, 30 Nov 2023 09:10:07 UTC (3,416 KB)"
"143","Constrained re-calibration of Reynolds-averaged Navier-Stokes models","Yuanwei Bin, George Huang, Robert Kunz, Xiang I A Yang","Fluid Dynamics (physics.flu-dyn)","The constants and functions in Reynolds-averaged Navier Stokes (RANS) turbulence models are coupled. Consequently, modifications of a RANS model often negatively impact its basic calibrations, which is why machine-learned augmentations are often detrimental outside the training dataset. A solution to this is to identify the degrees of freedom that do not affect the basic calibrations and only modify these identified degrees of freedom when re-calibrating the baseline model to accommodate a specific application. This approach is colloquially known as the ""rubber-band"" approach, which we formally call ""constrained model re-calibration"" in this article. To illustrate the efficacy of the approach, we identify the degrees of freedom in the Spalart-Allmaras (SA) model that do not affect the log law calibration. By subsequently interfacing data-based methods with these degrees of freedom, we train models to solve historically challenging flow scenarios, including the round-jet/plane-jet anomaly, airfoil stall, secondary flow separation, and recovery after separation. In addition to good performance inside the training dataset, the trained models yield similar performance as the baseline model outside the training dataset.","Fri, 13 Oct 2023 19:20:27 UTC (16,498 KB)"
"144","Optimization of Federated Learning's Client Selection for Non-IID Data Based on Grey Relational Analysis","Shuaijun Chen, Omid Tavallaie, Michael Henri Hambali, Seid Miad Zandavi, Hamed Haddadi, Nicholas Lane, Song Guo, Albert Y. Zomaya","Distributed, Parallel, and Cluster Computing (cs.DC)","Federated learning (FL) is a novel distributed learning framework designed for applications with privacy-sensitive data. Without sharing data, FL trains local models on individual devices and constructs the global model on the server by performing model aggregation. However, to reduce the communication cost, the participants in each training round are randomly selected, which significantly decreases the training efficiency under data and device heterogeneity. To address this issue, in this paper, we introduce a novel approach that considers the data distribution and computational resources of devices to select the clients for each training round. Our proposed method performs client selection based on the Grey Relational Analysis (GRA) theory by considering available computational resources for each client, the training loss, and weight divergence. To examine the usability of our proposed method, we implement our contribution on Amazon Web Services (AWS) by using the TensorFlow library of Python. We evaluate our algorithm's performance in different setups by varying the learning rate, network size, the number of selected clients, and the client selection round. The evaluation results show that our proposed algorithm enhances the performance significantly in terms of test accuracy and the average client's waiting time compared to state-of-the-art methods, federated averaging and Pow-d.","Thu, 12 Oct 2023 09:06:56 UTC (9,738 KB)[v2] Sat, 20 Jan 2024 05:01:13 UTC (24,902 KB)[v3] Wed, 24 Jan 2024 04:55:22 UTC (24,900 KB)"
"145","A Discrepancy Aware Framework for Robust Anomaly Detection","Yuxuan Cai, Dingkang Liang, Dongliang Luo, Xinwei He, Xin Yang, Xiang Bai","Computer Vision and Pattern Recognition (cs.CV)","Defect detection is a critical research area in artificial intelligence. Recently, synthetic data-based self-supervised learning has shown great potential on this task. Although many sophisticated synthesizing strategies exist, little research has been done to investigate the robustness of models when faced with different strategies. In this paper, we focus on this issue and find that existing methods are highly sensitive to them. To alleviate this issue, we present a Discrepancy Aware Framework (DAF), which demonstrates robust performance consistently with simple and cheap strategies across different anomaly detection benchmarks. We hypothesize that the high sensitivity to synthetic data of existing self-supervised methods arises from their heavy reliance on the visual appearance of synthetic data during decoding. In contrast, our method leverages an appearance-agnostic cue to guide the decoder in identifying defects, thereby alleviating its reliance on synthetic appearance. To this end, inspired by existing knowledge distillation methods, we employ a teacher-student network, which is trained based on synthesized outliers, to compute the discrepancy map as the cue. Extensive experiments on two challenging datasets prove the robustness of our method. Under the simple synthesis strategies, it outperforms existing methods by a large margin. Furthermore, it also achieves the state-of-the-art localization performance. Code is available at: this https URL.","Wed, 11 Oct 2023 15:21:40 UTC (1,547 KB)"
"146","Evaluating causal effects on time-to-event outcomes in an RCT in Oncology with treatment discontinuation due to adverse events","Veronica Ballerini, Björn Bornkamp, Alessandra Mattei, Fabrizia Mealli, Craig Wang, Yufen Zhang","Applications (stat.AP)","In clinical trials, patients sometimes discontinue study treatments prematurely due to reasons such as adverse events. Treatment discontinuation occurs after the randomisation as an intercurrent event, making causal inference more challenging. The Intention-To-Treat (ITT) analysis provides valid causal estimates of the effect of treatment assignment; still, it does not take into account whether or not patients had to discontinue the treatment prematurely. We propose to deal with the problem of treatment discontinuation using principal stratification, recognised in the ICH E9(R1) addendum as a strategy for handling intercurrent events. Under this approach, we can decompose the overall ITT effect into principal causal effects for groups of patients defined by their potential discontinuation behaviour in continuous time. In this framework, we must consider that discontinuation happening in continuous time generates an infinite number of principal strata and that discontinuation time is not defined for patients who would never discontinue. An additional complication is that discontinuation time and time-to-event outcomes are subject to administrative censoring. We employ a flexible model-based Bayesian approach to deal with such complications. We apply the Bayesian principal stratification framework to analyse synthetic data based on a recent RCT in Oncology, aiming to assess the causal effects of a new investigational drug combined with standard of care vs. standard of care alone on progression-free survival. We simulate data under different assumptions that reflect real situations where patients' behaviour depends on critical baseline covariates. Finally, we highlight how such an approach makes it straightforward to characterise patients' discontinuation behaviour with respect to the available covariates with the help of a simulation study.","Tue, 10 Oct 2023 14:19:05 UTC (1,650 KB)"
"147","Cross-domain Robust Deepfake Bias Expansion Network for Face Forgery Detection","Weihua Liu, Lin Li, Chaochao Lin, Said Boumaraf","Computer Vision and Pattern Recognition (cs.CV)","The rapid advancement of deepfake technologies raises significant concerns about the security of face recognition systems. While existing methods leverage the clues left by deepfake techniques for face forgery detection, malicious users may intentionally manipulate forged faces to obscure the traces of deepfake clues and thereby deceive detection tools. Meanwhile, attaining cross-domain robustness for data-based methods poses a challenge due to potential gaps in the training data, which may not encompass samples from all relevant domains. Therefore, in this paper, we introduce a solution - a Cross-Domain Robust Bias Expansion Network (BENet) - designed to enhance face forgery detection. BENet employs an auto-encoder to reconstruct input faces, maintaining the invariance of real faces while selectively enhancing the difference between reconstructed fake faces and their original counterparts. This enhanced bias forms a robust foundation upon which dependable forgery detection can be built. To optimize the reconstruction results in BENet, we employ a bias expansion loss infused with contrastive concepts to attain the aforementioned objective. In addition, to further heighten the amplification of forged clues, BENet incorporates a Latent-Space Attention (LSA) module. This LSA module effectively captures variances in latent features between the auto-encoder's encoder and decoder, placing emphasis on inconsistent forgery-related information. Furthermore, BENet incorporates a cross-domain detector with a threshold to determine whether the sample belongs to a known distribution. The correction of classification results through the cross-domain detector enables BENet to defend against unknown deepfake attacks from cross-domain. Extensive experiments demonstrate the superiority of BENet compared with state-of-the-art methods in intra-database and cross-database evaluations.","Sun, 8 Oct 2023 11:30:22 UTC (675 KB)"
"148","Multi-rules mining algorithm for combinatorially exploded decision trees with modified Aitchison-Aitken function-based Bayesian optimization","Yuto Omae, Masaya Mori, Yohei Kakimoto","Machine Learning (cs.LG)","Decision trees offer the benefit of easy interpretation because they allow the classification of input data based on if--then rules. However, as decision trees are constructed by an algorithm that achieves clear classification with minimum necessary rules, the trees possess the drawback of extracting only minimum rules, even when various latent rules exist in data. Approaches that construct multiple trees using randomly selected feature subsets do exist. However, the number of trees that can be constructed remains at the same scale because the number of feature subsets is a combinatorial explosion. Additionally, when multiple trees are constructed, numerous rules are generated, of which several are untrustworthy and/or highly similar. Therefore, we propose ""MAABO-MT"" and ""GS-MRM"" algorithms that strategically construct trees with high estimation performance among all possible trees with small computational complexity and extract only reliable and non-similar rules, respectively. Experiments are conducted using several open datasets to analyze the effectiveness of the proposed method. The results confirm that MAABO-MT can discover reliable rules at a lower computational cost than other methods that rely on randomness. Furthermore, the proposed method is confirmed to provide deeper insights than single decision trees commonly used in previous studies. Therefore, MAABO-MT and GS-MRM can efficiently extract rules from combinatorially exploded decision trees.","Wed, 4 Oct 2023 07:55:51 UTC (2,132 KB)"
"149","Signature Methods in Stochastic Portfolio Theory","Christa Cuchiero, Janka Möller","Mathematical Finance (q-fin.MF)","In the context of stochastic portfolio theory we introduce a novel class of portfolios which we call linear path-functional portfolios. These are portfolios which are determined by certain transformations of linear functions of a collections of feature maps that are non-anticipative path functionals of an underlying semimartingale. As main example for such feature maps we consider the signature of the (ranked) market weights. We prove that these portfolios are universal in the sense that every continuous, possibly path-dependent, portfolio function of the market weights can be uniformly approximated by signature portfolios. We also show that signature portfolios can approximate the growth-optimal portfolio in several classes of non-Markovian market models arbitrarily well and illustrate numerically that the trained signature portfolios are remarkably close to the theoretical growth-optimal portfolios. Besides these universality features, the main numerical advantage lies in the fact that several optimization tasks like maximizing (expected) logarithmic wealth or mean-variance optimization within the class of linear path-functional portfolios reduce to a convex quadratic optimization problem, thus making it computationally highly tractable. We apply our method also to real market data based on several indices. Our results point towards out-performance on the considered out-of-sample data, also in the presence of transaction costs.","Tue, 3 Oct 2023 18:00:37 UTC (1,337 KB)"
"150","Sampling Multimodal Distributions with the Vanilla Score: Benefits of Data-Based Initialization","Frederic Koehler, Thuy-Duong Vuong","Machine Learning (cs.LG)","There is a long history, as well as a recent explosion of interest, in statistical and generative modeling approaches based on score functions -- derivatives of the log-likelihood of a distribution. In seminal works, Hyvärinen proposed vanilla score matching as a way to learn distributions from data by computing an estimate of the score function of the underlying ground truth, and established connections between this method and established techniques like Contrastive Divergence and Pseudolikelihood estimation. It is by now well-known that vanilla score matching has significant difficulties learning multimodal distributions. Although there are various ways to overcome this difficulty, the following question has remained unanswered -- is there a natural way to sample multimodal distributions using just the vanilla score? Inspired by a long line of related experimental works, we prove that the Langevin diffusion with early stopping, initialized at the empirical distribution, and run on a score function estimated from data successfully generates natural multimodal distributions (mixtures of log-concave distributions).","Tue, 3 Oct 2023 03:06:59 UTC (577 KB)"
